{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "222cac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import eval_metrics as em\n",
    "import wandb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89eddae",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "006b2c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/users1/liqe/TeamLab_phonetics/TeamLab/wandb/run-20250702_090118-lf9i44gy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/lf9i44gy' target=\"_blank\">Training_05</a></strong> to <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/lf9i44gy' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/lf9i44gy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project = \"teamlab_deepfake\",\n",
    "    name = \"Training_05\",     #NOTE: set manually\n",
    "    notes = None,\n",
    "    tags = [\"ALL_FEATURE\", \"COMBINED_MODEL\", \"HNR\", \"PITCH\", \"JITTER&SHIMMER\", \"MFCC\"],\n",
    "    config={\n",
    "        #NOTE: set manually\n",
    "        \"model\": \"SpoofEnsemble\",   #   SpoofEnsemble/LSTM_FFN_classifier/CNN_classifier\n",
    "        \"dataset\": \"ASVSpoof19_LA\",    \n",
    "        \"feature\": \"MFCC&Prosody\",\n",
    "        \"attack_type\": \"all\",   # all/A01/A02/A03/A04/A05/A06\n",
    "        \"loss_function\": \"weighted_CE\",\n",
    "        #\n",
    "        \"epochs\": 70,\n",
    "        \"batch_size\": 32,\n",
    "        \"oversampling\": True,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"dropout_rate\": 0.3,\n",
    "        # lstm layer\n",
    "        \"lstm_input_dim\": 2,\n",
    "        \"lstm_hidden_dim\": 128,\n",
    "        \"bidirectional\": True,\n",
    "        \"lstm_n_layers\":1,\n",
    "        # fnn layer\n",
    "        \"ffn_dims\": [11, 64], # in, out -\n",
    "        # cnn layer\n",
    "        \"cnn_channels\": [1, 16, 32, 64],   #in, out -\n",
    "        \"conv_kernel\": (3,3),\n",
    "        \"pool_kernel\": (2,2),\n",
    "        \"cnn_padding\": 1,\n",
    "        # random seeds\n",
    "        \"seeds\": [0, 7, 42]\n",
    "    },\n",
    ")\n",
    "\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b71e6",
   "metadata": {},
   "source": [
    ">NOTE: attack types are evenly distributed in training and dev dataset, and each has higher number than genuine voices, so no further balancing is needed>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "621b14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PITCH_COLUMN = 'PITCH'\n",
    "HNR_COLUMN = 'HNR'\n",
    "JITTER_COLUMN = 'JITTER'\n",
    "SHIMMER_COLUMN = 'SHIMMER'\n",
    "MFCC_COLUMN = 'MFCC'\n",
    "LABEL_COLUMN = 'LABEL'      \n",
    "                           \n",
    "NAN_REPLACEMENT_VALUE = 0.0  \n",
    "PADDING_VALUE = 0.0         \n",
    "LABEL_BONAFIDE = 1\n",
    "LABEL_SPOOF = 0\n",
    "\n",
    "train_features_path = '/home/users1/liqe/TeamLab_phonetics/merged_train_com.pkl'\n",
    "dev_features_path = '/home/users1/liqe/TeamLab_phonetics/merged_dev_com.pkl'\n",
    "\n",
    "df_train = pd.read_pickle(train_features_path)\n",
    "df_dev = pd.read_pickle(dev_features_path)\n",
    "\n",
    "# NOTE: if training on a specific attack type\n",
    "if config.attack_type != \"all\":\n",
    "    df_train = df_train[df_train['ATTACK_TYPE']==(config.attack_type)]\n",
    "    df_dev = df_dev[df_dev['ATTACK_TYPE']==(config.attack_type)]\n",
    "elif config.attack_type == \"all\":\n",
    "    pass\n",
    "elif config.attack_type != (\"A01\" or \"A02\" or \"A03\" or \"A04\" or \"A05\" or \"A06\"):\n",
    "    print(\"WARNING: invalid attack type.\")\n",
    "\n",
    "# inspect\n",
    "# print(df_train.head())\n",
    "# print(df_train.groupby('ATTACK_TYPE').count())\n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(df_dev.head())\n",
    "# print(df_dev.groupby('ATTACK_TYPE').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fb4c6",
   "metadata": {},
   "source": [
    "#### Set the random seeds for replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5173b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed):\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9ec96",
   "metadata": {},
   "source": [
    "### Training Data Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f385ade",
   "metadata": {},
   "source": [
    ">NOTE: training audio & labels are matched, dev are not (Solved: excessive rows are deleted beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d12dd51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled X (DataFrame) head:\n",
      "       AUDIO_ID ATTACK_TYPE  \\\n",
      "0  LA_T_1000137         A04   \n",
      "1  LA_T_1000406           -   \n",
      "2  LA_T_1000648         A01   \n",
      "3  LA_T_1000824         A04   \n",
      "4  LA_T_1001074         A03   \n",
      "\n",
      "                                               PITCH  \\\n",
      "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  [nan, nan, nan, nan, nan, 0.35835335, 0.350411...   \n",
      "3  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "                                                 HNR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7987432, 0.79...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                              JITTER  \\\n",
      "0  [0.30073947, 0.23022015, 0.26707897, 0.2538646...   \n",
      "1  [0.1494679, 0.09972349, 0.086890295, 0.0791289...   \n",
      "2  [0.13972145, 0.05122372, 0.123514704, 0.096691...   \n",
      "3  [0.28089172, 0.2684494, 0.23122567, 0.24996407...   \n",
      "4  [0.14094485, 0.068655394, 0.07130514, 0.062871...   \n",
      "\n",
      "                                             SHIMMER  \\\n",
      "0  [0.27033818, 0.33233136, 0.11353744, 0.1519924...   \n",
      "1  [0.13012205, 0.15872449, 0.059600886, 0.081321...   \n",
      "2  [0.28141773, 0.3631905, 0.12680757, 0.17373542...   \n",
      "3  [0.2846507, 0.35503966, 0.13182917, 0.15244015...   \n",
      "4  [0.16095506, 0.21579938, 0.039854582, 0.081848...   \n",
      "\n",
      "                                                MFCC  \n",
      "0  [[0.14843875, 0.16200094, 0.18541528, 0.279557...  \n",
      "1  [[0.30532825, 0.3215196, 0.31294125, 0.3068853...  \n",
      "2  [[0.22124906, 0.34767622, 0.5816188, 0.6628496...  \n",
      "3  [[0.11835651, 0.12180926, 0.11639575, 0.117103...  \n",
      "4  [[0.19357309, 0.19469197, 0.19534206, 0.195999...  \n",
      "\n",
      "Resampled y (Series) head:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: LABEL, dtype: int8\n",
      "\n",
      "Resampled class distribution (from y_resampled_series):\n",
      "Counter({0: 22799, 1: 22799})\n",
      "\n",
      "Combined Resampled DataFrame head:\n",
      "       AUDIO_ID ATTACK_TYPE  \\\n",
      "0  LA_T_1000137         A04   \n",
      "1  LA_T_1000406           -   \n",
      "2  LA_T_1000648         A01   \n",
      "3  LA_T_1000824         A04   \n",
      "4  LA_T_1001074         A03   \n",
      "\n",
      "                                               PITCH  \\\n",
      "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  [nan, nan, nan, nan, nan, 0.35835335, 0.350411...   \n",
      "3  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "                                                 HNR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7987432, 0.79...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                              JITTER  \\\n",
      "0  [0.30073947, 0.23022015, 0.26707897, 0.2538646...   \n",
      "1  [0.1494679, 0.09972349, 0.086890295, 0.0791289...   \n",
      "2  [0.13972145, 0.05122372, 0.123514704, 0.096691...   \n",
      "3  [0.28089172, 0.2684494, 0.23122567, 0.24996407...   \n",
      "4  [0.14094485, 0.068655394, 0.07130514, 0.062871...   \n",
      "\n",
      "                                             SHIMMER  \\\n",
      "0  [0.27033818, 0.33233136, 0.11353744, 0.1519924...   \n",
      "1  [0.13012205, 0.15872449, 0.059600886, 0.081321...   \n",
      "2  [0.28141773, 0.3631905, 0.12680757, 0.17373542...   \n",
      "3  [0.2846507, 0.35503966, 0.13182917, 0.15244015...   \n",
      "4  [0.16095506, 0.21579938, 0.039854582, 0.081848...   \n",
      "\n",
      "                                                MFCC  LABEL  \n",
      "0  [[0.14843875, 0.16200094, 0.18541528, 0.279557...      0  \n",
      "1  [[0.30532825, 0.3215196, 0.31294125, 0.3068853...      1  \n",
      "2  [[0.22124906, 0.34767622, 0.5816188, 0.6628496...      0  \n",
      "3  [[0.11835651, 0.12180926, 0.11639575, 0.117103...      0  \n",
      "4  [[0.19357309, 0.19469197, 0.19534206, 0.195999...      0  \n",
      "\n",
      "Combined Resampled DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45598 entries, 0 to 45597\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   AUDIO_ID     45598 non-null  object\n",
      " 1   ATTACK_TYPE  45598 non-null  object\n",
      " 2   PITCH        45598 non-null  object\n",
      " 3   HNR          45598 non-null  object\n",
      " 4   JITTER       45598 non-null  object\n",
      " 5   SHIMMER      45598 non-null  object\n",
      " 6   MFCC         45598 non-null  object\n",
      " 7   LABEL        45598 non-null  int8  \n",
      "dtypes: int8(1), object(7)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "Combined Resampled DataFrame class distribution:\n",
      "Counter({0: 22799, 1: 22799})\n"
     ]
    }
   ],
   "source": [
    "if config.oversampling:\n",
    "    X = df_train.drop('LABEL', axis=1)\n",
    "    y = df_train['LABEL']\n",
    "\n",
    "    over = RandomOverSampler(random_state=config.seeds[0])\n",
    "    X_resampled_np, y_resampled_np = over.fit_resample(X, y) \n",
    "\n",
    "    X_resampled_df = pd.DataFrame(X_resampled_np, columns=X.columns)\n",
    "    y_resampled_series = pd.Series(y_resampled_np, name=y.name)\n",
    "\n",
    "    print(\"\\nResampled X (DataFrame) head:\")\n",
    "    print(X_resampled_df.head())\n",
    "    print(\"\\nResampled y (Series) head:\")\n",
    "    print(y_resampled_series.head())\n",
    "    print(\"\\nResampled class distribution (from y_resampled_series):\")\n",
    "    print(Counter(y_resampled_series))\n",
    "\n",
    "    df_train = pd.concat([X_resampled_df, y_resampled_series], axis=1)\n",
    "\n",
    "    print(\"\\nCombined Resampled DataFrame head:\")\n",
    "    print(df_train.head())\n",
    "    print(\"\\nCombined Resampled DataFrame info:\")\n",
    "    df_train.info()\n",
    "    print(\"\\nCombined Resampled DataFrame class distribution:\")\n",
    "    print(Counter(df_train['LABEL'])) # Verify target column in the new DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ec143",
   "metadata": {},
   "source": [
    "### Padding and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccbc2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASVDataset(Dataset):\n",
    "    def __init__(self, dataframe, pitch_col, hnr_col, jitter_col, shimmer_col, mfcc_col, label_col, nan_replacement=NAN_REPLACEMENT_VALUE):\n",
    "        \n",
    "        self.labels = []\n",
    "        self.processed_pitchhnr = []\n",
    "        self.global_features = []\n",
    "        self.processed_mfcc = []\n",
    "        \n",
    "        print(f\"Attempting to process {len(dataframe)} entries from DataFrame\")\n",
    "        found_count = 0\n",
    "        # Iterate through the DataFrame, process and pad the features\n",
    "        for index, row in dataframe.iterrows():  \n",
    "            if not np.isnan(row[label_col]):\n",
    "                self.labels.append(row[label_col])\n",
    "\n",
    "                pitch_sequence_raw = row[pitch_col]\n",
    "                processed_pitch = np.nan_to_num(pitch_sequence_raw, nan=nan_replacement)\n",
    "                \n",
    "                hnr_sequence_raw = row[hnr_col]\n",
    "                processed_hnr = np.nan_to_num(hnr_sequence_raw, nan=nan_replacement)\n",
    "\n",
    "                ### NOTE:need to pad the two sequences to the same length\n",
    "                max_length = max(len(processed_pitch), len(processed_hnr))\n",
    "                if len(processed_pitch) > len(processed_hnr):\n",
    "                    padding = np.zeros(max_length - len(processed_hnr), dtype=processed_hnr.dtype)\n",
    "                    processed_hnr = np.concatenate((processed_hnr, padding))\n",
    "                else:\n",
    "                    padding = np.zeros(max_length - len(processed_pitch), dtype=processed_pitch.dtype)\n",
    "                    processed_pitch = np.concatenate((processed_pitch, padding))\n",
    "\n",
    "                combined_features = np.stack((processed_pitch, processed_hnr), axis=-1) \n",
    "                self.processed_pitchhnr.append(torch.tensor(combined_features, dtype=torch.float32))\n",
    "\n",
    "                # process and combine jitter and shimmer to one sequence\n",
    "                processed_jitter = np.nan_to_num(row[jitter_col], nan=nan_replacement)\n",
    "                processed_shimmer = np.nan_to_num(row[shimmer_col], nan=nan_replacement)\n",
    "                jitter_shimmer = np.concatenate((processed_jitter, processed_shimmer))\n",
    "                self.global_features.append(torch.tensor(jitter_shimmer, dtype=torch.float32))\n",
    "                \n",
    "                # process mfcc\n",
    "                mfcc = row[mfcc_col]\n",
    "                # NOTE: need transpose for padding (time, feature_dim)\n",
    "                self.processed_mfcc.append(torch.tensor(mfcc, dtype=torch.float32).T)\n",
    "\n",
    "                found_count += 1\n",
    "        \n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long) # Assuming labels are integers for classification\n",
    "        print(f\"Successfully processed {found_count} samples out of {len(dataframe)} DataFrame entries.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of matched samples in the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns one sample from the dataset: a preprocessed pitch sequence and its label.\n",
    "        \"\"\"\n",
    "        label = self.labels[idx]\n",
    "        pitch_hnr = self.processed_pitchhnr[idx]\n",
    "        global_feature = self.global_features[idx]\n",
    "        mfcc = self.processed_mfcc[idx]\n",
    "        return label, pitch_hnr, global_feature, mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0f4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Collate Function for Dynamic Padding  ---\n",
    "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
    "    \"\"\"\n",
    "    Pads sequences within a batch to the same length.\n",
    "    \"\"\"\n",
    "    labels = [item[0] for item in batch]\n",
    "    pitch_hnrs = [item[1] for item in batch]\n",
    "    global_features = [item[2] for item in batch]\n",
    "    mfccs = [item[3] for item in batch]\n",
    "\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    pitchhnr_lengths = torch.tensor([len(seq) for seq in pitch_hnrs], dtype=torch.long)\n",
    "    padded_pitchhnrs = pad_sequence(pitch_hnrs, batch_first=True, padding_value=padding_value)\n",
    "    if padded_pitchhnrs.ndim == 2:     # lstm expects: [batch_size, sequence_length, feature_size]\n",
    "        padded_pitchhnrs = padded_pitchhnrs.unsqueeze(2)\n",
    "\n",
    "    global_features = torch.stack(global_features)\n",
    "\n",
    "    padded_mfccs = pad_sequence(mfccs, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    return labels, pitchhnr_lengths, padded_pitchhnrs, global_features, padded_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67d92225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to process 45598 entries from DataFrame\n",
      "Successfully processed 45598 samples out of 45598 DataFrame entries.\n",
      "Attempting to process 24844 entries from DataFrame\n",
      "Successfully processed 24844 samples out of 24844 DataFrame entries.\n",
      "\n",
      "--- Batch 1 ---\n",
      "  Labels (first 5): tensor([0, 1, 0, 1, 1])\n",
      "  Padded Sequences Shape: torch.Size([32, 446, 2])\n",
      "  Original Lengths (first 5): tensor([429, 270, 446, 219, 339])\n",
      "  Global Shape: torch.Size([32, 11])\n",
      "  MFCC Shape: torch.Size([32, 141, 60])\n"
     ]
    }
   ],
   "source": [
    "pitch_dataset_train = ASVDataset(dataframe=df_train,   # NOTE: oversampled (change upon need)\n",
    "                                    pitch_col=PITCH_COLUMN,\n",
    "                                    hnr_col=HNR_COLUMN,\n",
    "                                    jitter_col=JITTER_COLUMN,\n",
    "                                    shimmer_col=SHIMMER_COLUMN,\n",
    "                                    mfcc_col=MFCC_COLUMN,\n",
    "                                    label_col=LABEL_COLUMN,\n",
    "                                    nan_replacement=NAN_REPLACEMENT_VALUE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    pitch_dataset_train, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "pitch_dataset_dev = ASVDataset(dataframe=df_dev,   # NOTE: oversampled (change upon need)\n",
    "                                    pitch_col=PITCH_COLUMN,\n",
    "                                    hnr_col=HNR_COLUMN,\n",
    "                                    jitter_col=JITTER_COLUMN,\n",
    "                                    shimmer_col=SHIMMER_COLUMN,\n",
    "                                    mfcc_col=MFCC_COLUMN,\n",
    "                                    label_col=LABEL_COLUMN,\n",
    "                                    nan_replacement=NAN_REPLACEMENT_VALUE)\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    pitch_dataset_dev, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "## For inspection\n",
    "for i, batch_data in enumerate(train_dataloader):\n",
    "    # batch_data is a tuple\n",
    "    batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc = batch_data\n",
    "    print(f\"\\n--- Batch {i+1} ---\")\n",
    "    print(f\"  Labels (first 5): {batch_labels[:5]}\")\n",
    "    print(f\"  Padded Sequences Shape: {batch_pitchhnr.shape}\")\n",
    "    print(f\"  Original Lengths (first 5): {batch_lengths[:5]}\")\n",
    "    print(f\"  Global Shape: {batch_global.shape}\")\n",
    "    print(f\"  MFCC Shape: {batch_mfcc.shape}\")\n",
    "    \n",
    "\n",
    "    if i == 0: # Break after the first batch for inspection\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdbd83f",
   "metadata": {},
   "source": [
    "### Finding the weight (for weighted cross entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac071d",
   "metadata": {},
   "source": [
    "is there different ways calculating weitghs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f67837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = df_train['LABEL']   # NOTE:w/ oversampling\n",
    "#labels = df_train['LABEL']   # NOTE:w/o oversampling\n",
    "total = len(labels)\n",
    "count_bonafide = labels.value_counts().get(LABEL_BONAFIDE, 0)\n",
    "count_spoof =  total - count_bonafide\n",
    "weight_bonafide = total / (count_bonafide * 2)\n",
    "weight_spoof = total / (count_spoof * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d85b7",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a24da",
   "metadata": {},
   "source": [
    "#### LSTM&FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_FFN_branch(nn.Module):\n",
    "    def __init__(self, lstm_input_dim, lstm_hidden_dim, lstm_n_layers, bidirectional, \n",
    "                 ffn_dims):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_ffn_dim = (lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim) + ffn_dims[-1]\n",
    "        self.ffn_layers = nn.ModuleList()\n",
    "\n",
    "        # 1. lstm layer\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, \n",
    "                            lstm_hidden_dim, \n",
    "                            num_layers=lstm_n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            batch_first=True) # Input/output tensors are (batch, seq, feature)\n",
    "        # BN layer for stabalization\n",
    "        self.bn_lstm = nn.BatchNorm1d(self.lstm_ffn_dim)\n",
    "        \n",
    "        # 2. ffn layer\n",
    "        for i in range(len(ffn_dims) -1):\n",
    "            ffn_input_dim = ffn_dims[i]\n",
    "            ffn_hidden_dim = ffn_dims[i+1]\n",
    "            ffn_block = nn.Sequential(\n",
    "                nn.Linear(ffn_input_dim, ffn_hidden_dim),\n",
    "                nn.BatchNorm1d(ffn_hidden_dim),    # BN layer for stabalization\n",
    "                nn.ReLU())\n",
    "            self.ffn_layers.append(ffn_block)\n",
    "        \n",
    "        \n",
    "    def forward(self, pitch_hnrs, pitchhnr_lengths, global_features):\n",
    "      \n",
    "        # 1. Pack sequence\n",
    "        ### Compute actual data and ignore the padded values\n",
    "        packed_input = rnn_utils.pack_padded_sequence(pitch_hnrs, pitchhnr_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # 2. Pass packed sequence through LSTM\n",
    "        ### packed_output: Hidden states for every time step.\n",
    "        ### hidden: The final hidden state (summary) of the entire sequence.\n",
    "        ### cell: The final cell state (long-term memory) of the entire sequence.\n",
    "        packed_output, (lstm_hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # 3. Concatenate the final forward and backward hidden states (if bidirectional)\n",
    "        if self.lstm.bidirectional:\n",
    "            lstm_hidden = torch.cat((lstm_hidden[-2,:,:], lstm_hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            lstm_hidden = lstm_hidden[-1,:,:]\n",
    "        lstm_hidden = self.bn_lstm(lstm_hidden)\n",
    "\n",
    "        # 4. Pass global features (jitter and shimmer) through the FFN\n",
    "        for layer in self.ffn_layers:\n",
    "            global_features = layer(global_features)\n",
    "        ffn_output = global_features\n",
    "\n",
    "        # 5. Concatenate the outputs from lstm and fnn\n",
    "        combined_output = torch.cat((lstm_hidden,ffn_output), dim=1)\n",
    "\n",
    "        return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00fda60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LSTM_FFN training alone \n",
    "class LSTM_FFN_classifer(nn.Module):\n",
    "    def __init__(self, lstm_ffn_out, out_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_ffn_layer = lstm_ffn_out\n",
    "        self.fc = nn.Linear(self.lstm_ffn_out.lstm_ffn_dim, out_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, pitch_hnrs, pitchhnr_lengths, global_features):\n",
    "\n",
    "        lstm_ffn_out = self.lstm_ffn_layer(pitch_hnrs, pitchhnr_lengths, global_features)\n",
    "        lstm_ffn_out = self.dropout(lstm_ffn_out)\n",
    "        output = self.fc(lstm_ffn_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba600f70",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "290b852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_branch(nn.Module):\n",
    "    def __init__(self, cnn_channels, conv_kernel, pool_kernel, cnn_padding):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_dim = cnn_channels[-1]\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(cnn_channels)-2):\n",
    "            cnn_in = cnn_channels[i]\n",
    "            cnn_out = cnn_channels[i+1]\n",
    "            conv_block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=cnn_in, out_channels=cnn_out, kernel_size=conv_kernel, padding=cnn_padding),\n",
    "                nn.BatchNorm2d(cnn_out),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=pool_kernel))\n",
    "            self.conv_layers.append(conv_block)\n",
    "\n",
    "        # final layer of CNN\n",
    "        final_in = cnn_channels[-2]\n",
    "        final_out = cnn_channels[-1]\n",
    "\n",
    "        conv_final = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=final_in, out_channels=final_out, kernel_size=conv_kernel, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(final_out),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1))  # Output size: [batch, 64, 1, 1]\n",
    "        )\n",
    "        self.conv_layers.append(conv_final)\n",
    "        \n",
    "    def forward(self, mfccs):\n",
    "\n",
    "        # expected shape (batch_size, in_channel, height, width) -> unsqeeze\n",
    "        mfccs = mfccs.unsqueeze(1)\n",
    "\n",
    "        for layer in self.conv_layers:\n",
    "            mfccs = layer(mfccs)\n",
    "        cnn_out = mfccs.view(mfccs.size(0), -1)\n",
    "        \n",
    "        return cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49d26e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CNN training alone\n",
    "class CNN_classifer(nn.Module):\n",
    "    def __init__(self, cnn_out, out_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_layer = cnn_out\n",
    "        self.fc = nn.Linear(self.cnn_out.cnn_dim, out_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, mfccs):\n",
    "\n",
    "        cnn_out = self.cnn_layer(mfccs)\n",
    "        cnn_out = self.dropout(cnn_out)\n",
    "        output = self.fc(cnn_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942586f",
   "metadata": {},
   "source": [
    "#### Emsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbba4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoofEnsemble(nn.Module):\n",
    "    def __init__(self, lstm_ffn_branch, cnn_branch, output_dim, dropout):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_ffn_branch = lstm_ffn_branch\n",
    "        self.cnn_branch = cnn_branch\n",
    "\n",
    "        lstm_ffn_dim = lstm_ffn_branch.lstm_ffn_dim\n",
    "        cnn_dim = cnn_branch.cnn_dim\n",
    "        self.fc = nn.Linear(lstm_ffn_dim + cnn_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, pitch_hnrs, pitchhnr_lengths, global_features, mfccs):\n",
    "      \n",
    "        lstm_ffn_out = self.lstm_ffn_branch(pitch_hnrs, pitchhnr_lengths, global_features)\n",
    "        \n",
    "        # Get the output from the second branch\n",
    "        cnn_out = self.cnn_branch(mfccs)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        combined_features = torch.cat((lstm_ffn_out, cnn_out), dim=1)\n",
    "\n",
    "        # Apply dropout\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(combined_features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e0862",
   "metadata": {},
   "source": [
    "### Initiate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b6bdf",
   "metadata": {},
   "source": [
    "#### find the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c5ff2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa91379",
   "metadata": {},
   "source": [
    "#### find the class weights for WCE & set the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76bcf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([weight_bonafide, weight_spoof], dtype=torch.float32).to(DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean', weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e595d",
   "metadata": {},
   "source": [
    "#### Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5e02bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_model():\n",
    "    lstm_ffn_out= LSTM_FFN_branch(lstm_input_dim=config.lstm_input_dim, lstm_hidden_dim=config.lstm_hidden_dim, lstm_n_layers=config.lstm_n_layers, bidirectional=config.bidirectional,\n",
    "                    ffn_dims=config.ffn_dims).to(DEVICE)\n",
    "    cnn_out = CNN_branch(cnn_channels=config.cnn_channels, conv_kernel=config.conv_kernel, pool_kernel=config.pool_kernel, cnn_padding=config.cnn_padding).to(DEVICE)\n",
    "\n",
    "    if config.model==\"SpoofEnsemble\":\n",
    "        model = SpoofEnsemble(lstm_ffn_branch=lstm_ffn_out, cnn_branch=cnn_out, output_dim=2, dropout=config.dropout_rate).to(DEVICE)\n",
    "    elif config.model==\"LSTM_FFN_classifier\":\n",
    "        model = LSTM_FFN_classifer(lstm_ffn_out=lstm_ffn_out, output_dim=2, dropout=config.dropout_rate).to(DEVICE)\n",
    "    elif config.model==\"CNN_classifier\":\n",
    "        model = CNN_classifer(cnn_out=cnn_out, out_dim=2, dropout=config.dropout_rate).to(DEVICE)\n",
    "    else:\n",
    "        print(\"WARNING: invalid model name.\")\n",
    "    return model\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(reduction='mean', weight=class_weights)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# print(f\"DEBUG: Initial FFN_Linear WEIGHTS:\\n{model.ffn_linear.weight.detach().cpu().numpy()}\")\n",
    "# print(f\"DEBUG: Initial FFN_Linear BIAS:\\n{model.ffn_linear.bias.detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0614e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7882ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(data_loader, model, criterion):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    scores_bonafide = []\n",
    "    scores_spoof = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
    "        for batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc in data_loader:\n",
    "            \n",
    "            batch_labels = batch_labels.to(DEVICE)\n",
    "            batch_pitchhnr = batch_pitchhnr.to(DEVICE)\n",
    "            batch_global = batch_global.to(DEVICE)\n",
    "            batch_mfcc = batch_mfcc.to(DEVICE)\n",
    "\n",
    "            # Forward pass: Get model outputs (logits)\n",
    "            logits = model(batch_pitchhnr, batch_lengths, batch_global, batch_mfcc)\n",
    "            \n",
    "            # Calculate loss for the current batch\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            total_loss += loss.item() * batch_labels.size(0) # Accumulate loss, weighted by batch size\n",
    "\n",
    "            # for EER\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            for i in range(len(batch_labels)):\n",
    "                current_label = batch_labels[i]\n",
    "                current_score = probabilities[i]\n",
    "\n",
    "                if current_label == LABEL_BONAFIDE:\n",
    "                    scores_bonafide.append(current_score[LABEL_BONAFIDE].cpu())     # numpy is cpu only, need to move tensor from gpu\n",
    "                elif current_label == LABEL_SPOOF:\n",
    "                    scores_spoof.append(current_score[LABEL_BONAFIDE].cpu())\n",
    "            \n",
    "            total_samples += batch_labels.size(0) # Count number of samples in this batch\n",
    "\n",
    "    average_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    scores_bonafide_np = np.array(scores_bonafide)    \n",
    "    scores_spoof_np = np.array(scores_spoof)\n",
    "    eer, threshold = em.compute_eer(scores_bonafide_np, scores_spoof_np)\n",
    "\n",
    "    all_scores = np.concatenate((scores_bonafide_np, scores_spoof_np))\n",
    "    labels_true = np.concatenate((np.ones_like(scores_bonafide_np), np.zeros_like(scores_spoof_np)))\n",
    "    labels_pred = (all_scores >= threshold).astype(int)\n",
    "    \n",
    "    return average_loss, eer, threshold, labels_true, labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05672159",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dca569",
   "metadata": {},
   "source": [
    ">note: in wandb, scalers logs for every epoch, plots get overwritten (but still saved in artifacts?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c10873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(criterion, train_dataloader, dev_dataloader, num_epochs,\n",
    "                min_eer, best_model_filename):\n",
    "\n",
    "    model = initiate_model()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    print(f\"Training started on device: {DEVICE}\")\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    # Initial metric dictionary for the progress bar\n",
    "    metric_dict = {'train_loss': 'N/A', 'val_loss': 'N/A', 'val_eer': 'N/A', 'val_threshold': 'N/A'}\n",
    "\n",
    "    # Evaluate on validation set first to get a baseline\n",
    "    print(\"Evaluating on validation set before training...\")\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    val_loss_initial, val_eer_initial, threshold_initial, labels_true, labels_pred = evaluate_classifier(dev_dataloader, model, criterion)\n",
    "    metric_dict.update({'val_loss': f'{val_loss_initial:.3f}', 'val_eer': f'{val_eer_initial*100:.2f}%', 'val_threshold': f'{threshold_initial*100:.2f}%'})\n",
    "    print(f\"Initial Validation - Loss: {val_loss_initial:.4f}, EER: {val_eer_initial*100:.2f}%, Threshold: {threshold_initial*100:.2f}%\")\n",
    "\n",
    "    # Progress bar setup\n",
    "    total_steps = num_epochs * len(train_dataloader)\n",
    "    pbar = tqdm(total=total_steps, initial=0, postfix=metric_dict, unit=\"batch\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode (enables dropout, etc.)\n",
    "        pbar.set_description(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        num_train_batches = 0\n",
    "\n",
    "        for batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc in train_dataloader:\n",
    "            # Move data to the specified device\n",
    "            # batch_lengths are used by pack_padded_sequence which expects them on CPU\n",
    "            batch_labels = batch_labels.to(DEVICE)\n",
    "            batch_pitchhnr = batch_pitchhnr.to(DEVICE)\n",
    "            batch_global = batch_global.to(DEVICE)\n",
    "            batch_mfcc = batch_mfcc.to(DEVICE)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: Get model outputs (logits)\n",
    "            logits = model(batch_pitchhnr, batch_lengths, batch_global, batch_mfcc)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            # --- FOR GRADIENT CLIPPING ---\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics for progress bar and logging\n",
    "            running_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "            \n",
    "            pbar.update(1) # Increment progress bar by one batch\n",
    "            metric_dict.update({'train_loss': f'{loss.item():.3f}'}) # Current batch loss\n",
    "            pbar.set_postfix(metric_dict)\n",
    "        \n",
    "        # Calculate average training loss for the epoch\n",
    "        avg_epoch_train_loss = running_train_loss / num_train_batches if num_train_batches > 0 else 0.0\n",
    "        metric_dict.update({'train_loss': f'{avg_epoch_train_loss:.3f}'}) # Average epoch loss\n",
    "        \n",
    "        # Evaluate on validation set after each epoch\n",
    "        avg_val_loss, val_eer, val_threshold, labels_true, labels_pred = evaluate_classifier(dev_dataloader, model, criterion)\n",
    "        \n",
    "        # Update with latest validation metrics\n",
    "        metric_dict.update({'val_loss': f'{avg_val_loss:.3f}', 'val_eer': f'{val_eer*100:.2f}%', 'val_threshold': f'{val_threshold*100:.2f}%'})\n",
    "        pbar.set_postfix(metric_dict)\n",
    "        \n",
    "        # Optional: Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1} Summary: Avg Train Loss: {avg_epoch_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, EER: {val_eer*100:.2f}%, Threshold: {val_threshold*100:.2f}%\")\n",
    "\n",
    "        # log the train\\dev loss and the eer & threshold\n",
    "        run.log({\"train_loss\": avg_epoch_train_loss, \"dev_loss\": avg_val_loss, \n",
    "                   \"dev_eer\": val_eer, \"dev_threshold\":val_threshold, \"epoch\": epoch + 1})\n",
    "        \n",
    "        # update min eer and optimal model\n",
    "        if val_eer < min_eer:\n",
    "            min_eer = val_eer\n",
    "            torch.save(model.state_dict(), best_model_filename)\n",
    "            print(f\"Epoch {epoch+1}: New best model saved to '{best_model_filename}' with EER: {min_eer:.4f}\")\n",
    "\n",
    "            run.summary['best_validation_eer'] = min_eer\n",
    "            run.summary['best_eer_epoch'] = epoch + 1\n",
    "            run.summary['validation_loss_at_best_eer'] = avg_val_loss\n",
    "\n",
    "            # log the report and confusion matrix\n",
    "            class_names = ['SPOOF', 'BONAFIDE']     #NOTE: the order matters, need to match labels\n",
    "            report_columns =  [\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"]\n",
    "            class_report = classification_report(labels_true, labels_pred, labels=[0, 1],\n",
    "                                        target_names=class_names).splitlines()\n",
    "            report_table = []\n",
    "            for line in class_report[2:(len(class_names)+2)]:\n",
    "                report_table.append(line.split())\n",
    "            run.log({\"Confusion Matix\": wandb.plot.confusion_matrix(y_true=labels_true, preds=labels_pred, class_names=class_names),\n",
    "                    \"Classification Report\": wandb.Table(data=report_table, columns=report_columns)})\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"Training finished.\")\n",
    "    return min_eer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357368b",
   "metadata": {},
   "source": [
    "#### Start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00816c",
   "metadata": {},
   "source": [
    ">note: only partially deterministic for adaptivemaxpooling does not support the feature yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2c89dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Trial with Seed: 0 ---\n",
      "Training started on device: cuda\n",
      "Evaluating on validation set before training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 256 elements not 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Starting Trial with Seed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# set_seed(seed)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# torch.use_deterministic_algorithms(True, warn_only=True)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m min_eer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_eer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(criterion, train_dataloader, dev_dataloader, num_epochs, min_eer, best_model_filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating on validation set before training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m val_loss_initial, val_eer_initial, threshold_initial, labels_true, labels_pred \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m metric_dict\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss_initial\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_eer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_eer_initial\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold_initial\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Validation - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss_initial\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, EER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_eer_initial\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold_initial\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[60], line 21\u001b[0m, in \u001b[0;36mevaluate_classifier\u001b[0;34m(data_loader, model, criterion)\u001b[0m\n\u001b[1;32m     18\u001b[0m batch_mfcc \u001b[38;5;241m=\u001b[39m batch_mfcc\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass: Get model outputs (logits)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_pitchhnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate loss for the current batch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, batch_labels)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 17\u001b[0m, in \u001b[0;36mSpoofEnsemble.forward\u001b[0;34m(self, pitch_hnrs, pitchhnr_lengths, global_features, mfccs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pitch_hnrs, pitchhnr_lengths, global_features, mfccs):\n\u001b[0;32m---> 17\u001b[0m     lstm_ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_ffn_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpitch_hnrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitchhnr_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Get the output from the second branch\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     cnn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_branch(mfccs)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[52], line 47\u001b[0m, in \u001b[0;36mLSTM_FFN_branch.forward\u001b[0;34m(self, pitch_hnrs, pitchhnr_lengths, global_features)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     lstm_hidden \u001b[38;5;241m=\u001b[39m lstm_hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:]\n\u001b[0;32m---> 47\u001b[0m lstm_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 4. Pass global features (jitter and shimmer) through the FFN\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_layers:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch0/lib/python3.11/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 256 elements not 128"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = config.epochs\n",
    "min_eer = float('inf')\n",
    "best_model_filename = 'best_model'\n",
    "\n",
    "for seed in config.seeds:\n",
    "    print(f\"\\n--- Starting Trial with Seed: {seed} ---\")\n",
    "    # set_seed(seed)\n",
    "    # torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    min_eer = train_model(criterion, train_dataloader, dev_dataloader, NUM_EPOCHS, min_eer, best_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7ece4",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2840319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging the best model (best_model) to W&B Artifacts...\n",
      "Best model logged as W&B Artifact.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_eer</td><td></td></tr><tr><td>dev_loss</td><td></td></tr><tr><td>dev_threshold</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eer_epoch</td><td>50</td></tr><tr><td>best_validation_eer</td><td>0.00553</td></tr><tr><td>dev_eer</td><td>0.0142</td></tr><tr><td>dev_loss</td><td>0.04515</td></tr><tr><td>dev_threshold</td><td>0.00019</td></tr><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.00279</td></tr><tr><td>validation_loss_at_best_eer</td><td>0.02127</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Training_04</strong> at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/bb0a5r0h' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/bb0a5r0h</a><br> View project at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake</a><br>Synced 5 W&B file(s), 42 media file(s), 76 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250701_235840-bb0a5r0h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished.\n"
     ]
    }
   ],
   "source": [
    "if min_eer != float('inf'):\n",
    "    print(f\"Logging the best model ({best_model_filename}) to W&B Artifacts...\")\n",
    "    best_model_artifact = wandb.Artifact(\n",
    "        name=f\"{run.id}-best-model\", # Using run ID for uniqueness\n",
    "        type=\"model\",\n",
    "        description=f\"Best model according to EER ({min_eer:.4f}) achieved at epoch {run.summary.get('best_eer_epoch', 'N/A')}.\",\n",
    "        metadata={\"best_eer\": min_eer, \"epoch_of_best_eer\": run.summary.get('best_eer_epoch', 'N/A')}\n",
    "    )\n",
    "    best_model_artifact.add_file(best_model_filename) # Add the saved file\n",
    "    wandb.run.log_artifact(best_model_artifact, aliases=[\"best_eer_model\"]) # Add an alias\n",
    "    print(\"Best model logged as W&B Artifact.\")\n",
    "else:\n",
    "    print(\"No model was saved as best_eer did not improve from its initial value.\")\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(\"W&B run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0200f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
