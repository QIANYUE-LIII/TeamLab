{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "222cac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import eval_metrics as em\n",
    "import wandb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89eddae",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "006b2c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_eer</td><td>▁</td></tr><tr><td>dev_loss</td><td>▁</td></tr><tr><td>dev_threshold</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eer_epoch</td><td>1</td></tr><tr><td>best_validation_eer</td><td>0.03798</td></tr><tr><td>dev_eer</td><td>0.03798</td></tr><tr><td>dev_loss</td><td>0.08987</td></tr><tr><td>dev_threshold</td><td>0.00274</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>train_loss</td><td>0.11461</td></tr><tr><td>validation_loss_at_best_eer</td><td>0.08987</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">COMBINED_TEST</strong> at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/c02gv4dw' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/c02gv4dw</a><br> View project at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake</a><br>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250624_142417-c02gv4dw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/users1/liqe/TeamLab_phonetics/TeamLab/wandb/run-20250624_151648-yxvyt5pb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/yxvyt5pb' target=\"_blank\">COMBINED_MODEL_1</a></strong> to <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/yxvyt5pb' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/yxvyt5pb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project = \"teamlab_deepfake\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"model\": \"LSTM\",    #NOTE: set manually\n",
    "        \"dataset\": \"ASVSpoof19_LA_original\",    #NOTE: set manually\n",
    "        \"feature\": \"PITCH_HNR_scaled\",   #NOTE: set manually\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 32,\n",
    "        \"loss_function\": \"weighted_CE\",     #NOTE: set manually\n",
    "        \"dropout_rate\": 0,\n",
    "        # lstm layer\n",
    "        \"lstm_input_dim\": 2,\n",
    "        \"lstm_hidden_dim\": 64,\n",
    "        \"bidirectional\": False,\n",
    "        \"lstm_n_layers\":1,\n",
    "        # fnn layer\n",
    "        \"ffn_input_dim\": 11,\n",
    "        \"ffn_hidden_dim\": 64,\n",
    "        # cnn layer\n",
    "        \"cnn1_out\": 16,\n",
    "        \"cnn2_out\": 32,\n",
    "        \"cnn3_out\": 64,\n",
    "        \"conv_kernel\": (3,3),\n",
    "        \"pool_kernel\": (2,2),\n",
    "        \"cnn_padding\": 1\n",
    "    },\n",
    "    name = \"COMBINED_MODEL_1\",     #NOTE: set manually\n",
    "    notes = None,\n",
    "    tags = [\"ALL_FEATURE\", \"COMBINED_MODEL\", \"HNR\", \"PITCH\", \"JITTER&SHIMMER\", \"MFCC\"],\n",
    ")\n",
    "\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "621b14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PITCH_COLUMN = 'PITCH'\n",
    "HNR_COLUMN = 'HNR'\n",
    "JITTER_COLUMN = 'JITTER'\n",
    "SHIMMER_COLUMN = 'SHIMMER'\n",
    "MFCC_COLUMN = 'MFCC'\n",
    "AUDIO_ID_COLUMN = 'AUDIO_ID'\n",
    "LABEL_COLUMN = 'LABEL'\n",
    "ATTACK_COLOMN = 'ATTACK_TYPE'        \n",
    "                           \n",
    "NAN_REPLACEMENT_VALUE = 0.0  \n",
    "PADDING_VALUE = 0.0         \n",
    "LABEL_BONAFIDE = 1\n",
    "LABEL_SPOOF = 0\n",
    "\n",
    "train_features_path = '/home/users1/liqe/TeamLab_phonetics/merged_train_com.pkl'\n",
    "dev_features_path = '/home/users1/liqe/TeamLab_phonetics/merged_dev_com.pkl'\n",
    "\n",
    "df_train = pd.read_pickle(train_features_path)\n",
    "df_dev = pd.read_pickle(dev_features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9ec96",
   "metadata": {},
   "source": [
    "### Training Data Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f385ade",
   "metadata": {},
   "source": [
    ">NOTE: training audio & labels are matched, dev are not (Solved: excessive rows are deleted beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d12dd51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled X (DataFrame) head:\n",
      "       AUDIO_ID ATTACK_TYPE  \\\n",
      "0  LA_T_1000137         A04   \n",
      "1  LA_T_1000406           -   \n",
      "2  LA_T_1000648         A01   \n",
      "3  LA_T_1000824         A04   \n",
      "4  LA_T_1001074         A03   \n",
      "\n",
      "                                               PITCH  \\\n",
      "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  [nan, nan, nan, nan, nan, 0.35835335, 0.350411...   \n",
      "3  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "                                                 HNR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7987432, 0.79...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                              JITTER  \\\n",
      "0  [0.30073947, 0.23022015, 0.26707897, 0.2538646...   \n",
      "1  [0.1494679, 0.09972349, 0.086890295, 0.0791289...   \n",
      "2  [0.13972145, 0.05122372, 0.123514704, 0.096691...   \n",
      "3  [0.28089172, 0.2684494, 0.23122567, 0.24996407...   \n",
      "4  [0.14094485, 0.068655394, 0.07130514, 0.062871...   \n",
      "\n",
      "                                             SHIMMER  \\\n",
      "0  [0.27033818, 0.33233136, 0.11353744, 0.1519924...   \n",
      "1  [0.13012205, 0.15872449, 0.059600886, 0.081321...   \n",
      "2  [0.28141773, 0.3631905, 0.12680757, 0.17373542...   \n",
      "3  [0.2846507, 0.35503966, 0.13182917, 0.15244015...   \n",
      "4  [0.16095506, 0.21579938, 0.039854582, 0.081848...   \n",
      "\n",
      "                                                MFCC  \n",
      "0  [[0.14843875, 0.16200094, 0.18541528, 0.279557...  \n",
      "1  [[0.30532825, 0.3215196, 0.31294125, 0.3068853...  \n",
      "2  [[0.22124906, 0.34767622, 0.5816188, 0.6628496...  \n",
      "3  [[0.11835651, 0.12180926, 0.11639575, 0.117103...  \n",
      "4  [[0.19357309, 0.19469197, 0.19534206, 0.195999...  \n",
      "\n",
      "Resampled y (Series) head:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: LABEL, dtype: int8\n",
      "\n",
      "Resampled class distribution (from y_resampled_series):\n",
      "Counter({0: 22799, 1: 22799})\n",
      "\n",
      "Combined Resampled DataFrame head:\n",
      "       AUDIO_ID ATTACK_TYPE  \\\n",
      "0  LA_T_1000137         A04   \n",
      "1  LA_T_1000406           -   \n",
      "2  LA_T_1000648         A01   \n",
      "3  LA_T_1000824         A04   \n",
      "4  LA_T_1001074         A03   \n",
      "\n",
      "                                               PITCH  \\\n",
      "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  [nan, nan, nan, nan, nan, 0.35835335, 0.350411...   \n",
      "3  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "                                                 HNR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7987432, 0.79...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                              JITTER  \\\n",
      "0  [0.30073947, 0.23022015, 0.26707897, 0.2538646...   \n",
      "1  [0.1494679, 0.09972349, 0.086890295, 0.0791289...   \n",
      "2  [0.13972145, 0.05122372, 0.123514704, 0.096691...   \n",
      "3  [0.28089172, 0.2684494, 0.23122567, 0.24996407...   \n",
      "4  [0.14094485, 0.068655394, 0.07130514, 0.062871...   \n",
      "\n",
      "                                             SHIMMER  \\\n",
      "0  [0.27033818, 0.33233136, 0.11353744, 0.1519924...   \n",
      "1  [0.13012205, 0.15872449, 0.059600886, 0.081321...   \n",
      "2  [0.28141773, 0.3631905, 0.12680757, 0.17373542...   \n",
      "3  [0.2846507, 0.35503966, 0.13182917, 0.15244015...   \n",
      "4  [0.16095506, 0.21579938, 0.039854582, 0.081848...   \n",
      "\n",
      "                                                MFCC  LABEL  \n",
      "0  [[0.14843875, 0.16200094, 0.18541528, 0.279557...      0  \n",
      "1  [[0.30532825, 0.3215196, 0.31294125, 0.3068853...      1  \n",
      "2  [[0.22124906, 0.34767622, 0.5816188, 0.6628496...      0  \n",
      "3  [[0.11835651, 0.12180926, 0.11639575, 0.117103...      0  \n",
      "4  [[0.19357309, 0.19469197, 0.19534206, 0.195999...      0  \n",
      "\n",
      "Combined Resampled DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45598 entries, 0 to 45597\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   AUDIO_ID     45598 non-null  object\n",
      " 1   ATTACK_TYPE  45598 non-null  object\n",
      " 2   PITCH        45598 non-null  object\n",
      " 3   HNR          45598 non-null  object\n",
      " 4   JITTER       45598 non-null  object\n",
      " 5   SHIMMER      45598 non-null  object\n",
      " 6   MFCC         45598 non-null  object\n",
      " 7   LABEL        45598 non-null  int8  \n",
      "dtypes: int8(1), object(7)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "Combined Resampled DataFrame class distribution:\n",
      "Counter({0: 22799, 1: 22799})\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop('LABEL', axis=1)\n",
    "y = df_train['LABEL']\n",
    "\n",
    "over = RandomOverSampler(random_state=42)\n",
    "X_resampled_np, y_resampled_np = over.fit_resample(X, y) \n",
    "\n",
    "X_resampled_df = pd.DataFrame(X_resampled_np, columns=X.columns)\n",
    "y_resampled_series = pd.Series(y_resampled_np, name=y.name)\n",
    "\n",
    "print(\"\\nResampled X (DataFrame) head:\")\n",
    "print(X_resampled_df.head())\n",
    "print(\"\\nResampled y (Series) head:\")\n",
    "print(y_resampled_series.head())\n",
    "print(\"\\nResampled class distribution (from y_resampled_series):\")\n",
    "print(Counter(y_resampled_series))\n",
    "\n",
    "train_resampled = pd.concat([X_resampled_df, y_resampled_series], axis=1)\n",
    "\n",
    "print(\"\\nCombined Resampled DataFrame head:\")\n",
    "print(train_resampled.head())\n",
    "print(\"\\nCombined Resampled DataFrame info:\")\n",
    "train_resampled.info()\n",
    "print(\"\\nCombined Resampled DataFrame class distribution:\")\n",
    "print(Counter(train_resampled['LABEL'])) # Verify target column in the new DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bd026",
   "metadata": {},
   "source": [
    "### Scaling\n",
    ">note: need custom function to scale if not padded (solved: scaled data saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ec143",
   "metadata": {},
   "source": [
    "### Padding and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ccbc2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: CHANGE THE NAME LATER\n",
    "class ASVDataset(Dataset):\n",
    "    def __init__(self, dataframe, pitch_col, hnr_col, jitter_col, shimmer_col, mfcc_col, audio_id_col, label_col, nan_replacement=NAN_REPLACEMENT_VALUE):\n",
    "        \n",
    "        self.labels = []\n",
    "        self.processed_pitchhnr = []\n",
    "        self.global_features = []\n",
    "        self.processed_mfcc = []\n",
    "        \n",
    "        print(f\"Attempting to process {len(dataframe)} entries from DataFrame\")\n",
    "        found_count = 0\n",
    "        # Iterate through the DataFrame, process and pad the features\n",
    "        for index, row in dataframe.iterrows():  \n",
    "            if not np.isnan(row[label_col]):\n",
    "                self.labels.append(row[label_col])\n",
    "\n",
    "                pitch_sequence_raw = row[pitch_col]\n",
    "                processed_pitch = np.nan_to_num(pitch_sequence_raw, nan=nan_replacement)\n",
    "                \n",
    "                hnr_sequence_raw = row[hnr_col]\n",
    "                processed_hnr = np.nan_to_num(hnr_sequence_raw, nan=nan_replacement)\n",
    "\n",
    "                ### NOTE:need to pad the two sequences to the same length\n",
    "                max_length = max(len(processed_pitch), len(processed_hnr))\n",
    "                if len(processed_pitch) > len(processed_hnr):\n",
    "                    padding = np.zeros(max_length - len(processed_hnr), dtype=processed_hnr.dtype)\n",
    "                    processed_hnr = np.concatenate((processed_hnr, padding))\n",
    "                else:\n",
    "                    padding = np.zeros(max_length - len(processed_pitch), dtype=processed_pitch.dtype)\n",
    "                    processed_pitch = np.concatenate((processed_pitch, padding))\n",
    "\n",
    "                combined_features = np.stack((processed_pitch, processed_hnr), axis=-1) \n",
    "                self.processed_pitchhnr.append(torch.tensor(combined_features, dtype=torch.float32))\n",
    "\n",
    "                # process and combine jitter and shimmer to one sequence\n",
    "                processed_jitter = np.nan_to_num(row[jitter_col], nan=nan_replacement)\n",
    "                processed_shimmer = np.nan_to_num(row[shimmer_col], nan=nan_replacement)\n",
    "                jitter_shimmer = np.concatenate((processed_jitter, processed_shimmer))\n",
    "                self.global_features.append(torch.tensor(jitter_shimmer, dtype=torch.float32))\n",
    "                \n",
    "                # process mfcc\n",
    "                mfcc = row[mfcc_col]\n",
    "                # NOTE: need transpose for padding (time, feature_dim)\n",
    "                self.processed_mfcc.append(torch.tensor(mfcc, dtype=torch.float32).T)\n",
    "\n",
    "                found_count += 1\n",
    "        \n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long) # Assuming labels are integers for classification\n",
    "        print(f\"Successfully processed {found_count} samples out of {len(dataframe)} DataFrame entries.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of matched samples in the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns one sample from the dataset: a preprocessed pitch sequence and its label.\n",
    "        \"\"\"\n",
    "        label = self.labels[idx]\n",
    "        pitch_hnr = self.processed_pitchhnr[idx]\n",
    "        global_feature = self.global_features[idx]\n",
    "        mfcc = self.processed_mfcc[idx]\n",
    "        return label, pitch_hnr, global_feature, mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0f4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Collate Function for Dynamic Padding  ---\n",
    "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
    "    \"\"\"\n",
    "    Pads sequences within a batch to the same length.\n",
    "    \"\"\"\n",
    "    labels = [item[0] for item in batch]\n",
    "    pitch_hnrs = [item[1] for item in batch]\n",
    "    global_features = [item[2] for item in batch]\n",
    "    mfccs = [item[3] for item in batch]\n",
    "\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    pitchhnr_lengths = torch.tensor([len(seq) for seq in pitch_hnrs], dtype=torch.long)\n",
    "    padded_pitchhnrs = pad_sequence(pitch_hnrs, batch_first=True, padding_value=padding_value)\n",
    "    if padded_pitchhnrs.ndim == 2:     # lstm expects: [batch_size, sequence_length, feature_size]\n",
    "        padded_pitchhnrs = padded_pitchhnrs.unsqueeze(2)\n",
    "\n",
    "    global_features = torch.stack(global_features)\n",
    "\n",
    "    padded_mfccs = pad_sequence(mfccs, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    return labels, pitchhnr_lengths, padded_pitchhnrs, global_features, padded_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67d92225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to process 45598 entries from DataFrame\n",
      "Successfully processed 45598 samples out of 45598 DataFrame entries.\n",
      "Attempting to process 24844 entries from DataFrame\n",
      "Successfully processed 24844 samples out of 24844 DataFrame entries.\n",
      "\n",
      "--- Batch 1 ---\n",
      "  Labels (first 5): tensor([0, 1, 1, 0, 1])\n",
      "  Padded Sequences Shape: torch.Size([32, 585, 2])\n",
      "  Original Lengths (first 5): tensor([585, 266, 420, 226, 513])\n",
      "  Global Shape: torch.Size([32, 11])\n",
      "  MFCC Shape: torch.Size([32, 184, 60])\n"
     ]
    }
   ],
   "source": [
    "pitch_dataset_train = ASVDataset(dataframe=train_resampled,   # NOTE: oversampled (change upon need)\n",
    "                                     pitch_col=PITCH_COLUMN,\n",
    "                                     hnr_col=HNR_COLUMN,\n",
    "                                     jitter_col=JITTER_COLUMN,\n",
    "                                     shimmer_col=SHIMMER_COLUMN,\n",
    "                                     mfcc_col=MFCC_COLUMN,\n",
    "                                     audio_id_col=AUDIO_ID_COLUMN,\n",
    "                                     label_col=LABEL_COLUMN,\n",
    "                                     nan_replacement=NAN_REPLACEMENT_VALUE)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    pitch_dataset_train, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "pitch_dataset_dev = ASVDataset(dataframe=df_dev,   # NOTE: oversampled (change upon need)\n",
    "                                     pitch_col=PITCH_COLUMN,\n",
    "                                     hnr_col=HNR_COLUMN,\n",
    "                                     jitter_col=JITTER_COLUMN,\n",
    "                                     shimmer_col=SHIMMER_COLUMN,\n",
    "                                     mfcc_col=MFCC_COLUMN,\n",
    "                                     audio_id_col=AUDIO_ID_COLUMN,\n",
    "                                     label_col=LABEL_COLUMN,\n",
    "                                     nan_replacement=NAN_REPLACEMENT_VALUE)\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    pitch_dataset_dev, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "## For inspection\n",
    "for i, batch_data in enumerate(train_dataloader):\n",
    "    # batch_data is a tuple\n",
    "    batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc = batch_data\n",
    "    print(f\"\\n--- Batch {i+1} ---\")\n",
    "    print(f\"  Labels (first 5): {batch_labels[:5]}\")\n",
    "    print(f\"  Padded Sequences Shape: {batch_pitchhnr.shape}\")\n",
    "    print(f\"  Original Lengths (first 5): {batch_lengths[:5]}\")\n",
    "    print(f\"  Global Shape: {batch_global.shape}\")\n",
    "    print(f\"  MFCC Shape: {batch_mfcc.shape}\")\n",
    "    \n",
    "\n",
    "    if i == 0: # Break after the first batch for inspection\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdbd83f",
   "metadata": {},
   "source": [
    "### Finding the weight (for weighted cross entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac071d",
   "metadata": {},
   "source": [
    "is there different ways calculating weitghs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f67837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = train_resampled['LABEL']   # NOTE:w/ oversampling\n",
    "#labels = df_train['LABEL']   # NOTE:w/o oversampling\n",
    "total = len(labels)\n",
    "count_bonafide = labels.value_counts().get(LABEL_BONAFIDE, 0)\n",
    "count_spoof =  total - count_bonafide\n",
    "weight_bonafide = total / (count_bonafide * 2)\n",
    "weight_spoof = total / (count_spoof * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d85b7",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbba4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoofClassifier(nn.Module):\n",
    "    def __init__(self, lstm_input_dim, lstm_hidden_dim, lstm_n_layers, bidirectional, \n",
    "                 ffn_input_dim, ffn_hidden_dim, \n",
    "                 cnn1_out, cnn2_out, cnn3_out, conv_kernel, pool_kernel, cnn_padding,\n",
    "                 dropout, output_dim,):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. LSTM Layer\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, \n",
    "                            lstm_hidden_dim, \n",
    "                            num_layers=lstm_n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout=dropout if lstm_n_layers > 1 else 0,\n",
    "                            batch_first=True) # Input/output tensors are (batch, seq, feature)\n",
    "        # BN layer for stabalization\n",
    "        self.bn_lstm = nn.BatchNorm1d(lstm_hidden_dim)\n",
    "        \n",
    "        # 2. ffn layer\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(ffn_input_dim, ffn_hidden_dim),\n",
    "            nn.BatchNorm1d(ffn_hidden_dim),    # BN layer for stabalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout))\n",
    "        \n",
    "        # 3. cnn layer\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=cnn1_out, kernel_size=conv_kernel, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn1_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel)\n",
    "        )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn1_out, out_channels=cnn2_out, kernel_size=conv_kernel, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn2_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_kernel)\n",
    "        )\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn2_out, out_channels=cnn3_out, kernel_size=conv_kernel, padding=cnn_padding),\n",
    "            nn.BatchNorm2d(cnn3_out),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1))  # Output size: [batch, 64, 1, 1]\n",
    "        )\n",
    "        \n",
    "        # 4. Fully Connected Layer (Linear Layer)\n",
    "        self.fc = nn.Linear((lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim) + ffn_hidden_dim + cnn3_out, output_dim)\n",
    "        \n",
    "        # 5. Dropout Layer (for regularization on the output of LSTM)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, pitch_hnrs, pitchhnr_lengths, global_features, mfccs):\n",
    "      \n",
    "        # 1. Pack sequence\n",
    "        ### Compute actual data and ignore the padded values\n",
    "        packed_input = rnn_utils.pack_padded_sequence(pitch_hnrs, pitchhnr_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # 2. Pass packed sequence through LSTM\n",
    "        ### packed_output: Hidden states for every time step.\n",
    "        ### hidden: The final hidden state (summary) of the entire sequence.\n",
    "        ### cell: The final cell state (long-term memory) of the entire sequence.\n",
    "        packed_output, (lstm_hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # 3. Concatenate the final forward and backward hidden states (if bidirectional)\n",
    "        if self.lstm.bidirectional:\n",
    "            lstm_hidden = self.dropout(torch.cat((lstm_hidden[-2,:,:], lstm_hidden[-1,:,:]), dim=1))\n",
    "        else:\n",
    "            lstm_hidden = self.dropout(lstm_hidden[-1,:,:])\n",
    "        lstm_hidden = self.bn_lstm(lstm_hidden)\n",
    "\n",
    "        # 4. Pass global features (jitter and shimmer) through the FFN\n",
    "        ffn_output = self.ffn(global_features)\n",
    "\n",
    "        # 5. Pass mfcc features through the CNN\n",
    "        # expected shape (batch_size, in_channel, height, width) -> unsqeeze\n",
    "        mfccs = mfccs.unsqueeze(1)\n",
    "        cnn_out = self.cnn3(self.cnn2(self.cnn1(mfccs)))\n",
    "        cnn_out = cnn_out.view(cnn_out.size(0), -1)\n",
    "\n",
    "        # 6. Concatenate the outputs from lstm and fnn\n",
    "        combined_features = torch.cat((lstm_hidden,ffn_output,cnn_out), dim=1)\n",
    "\n",
    "        # 7. Pass the processed hidden state through the fully connected layer\n",
    "        output = self.fc(combined_features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e0862",
   "metadata": {},
   "source": [
    "### Initiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c5ff2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76bcf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([weight_bonafide, weight_spoof], dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5e02bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpoofClassifier(lstm_input_dim=config.lstm_input_dim, lstm_hidden_dim=config.lstm_hidden_dim, lstm_n_layers=config.lstm_n_layers, bidirectional=config.bidirectional,\n",
    "                 ffn_input_dim=config.ffn_input_dim, ffn_hidden_dim=config.ffn_hidden_dim,\n",
    "                 cnn1_out=config.cnn1_out, cnn2_out=config.cnn2_out, cnn3_out=config.cnn3_out, conv_kernel=config.conv_kernel, pool_kernel=config.pool_kernel, cnn_padding=config.cnn_padding,\n",
    "                 dropout=config.dropout_rate, output_dim=2).to(DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean', weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# print(f\"DEBUG: Initial FFN_Linear WEIGHTS:\\n{model.ffn_linear.weight.detach().cpu().numpy()}\")\n",
    "# print(f\"DEBUG: Initial FFN_Linear BIAS:\\n{model.ffn_linear.bias.detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0614e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7882ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(data_loader, model, criterion):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    scores_bonafide = []\n",
    "    scores_spoof = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
    "        for batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc in data_loader:\n",
    "            \n",
    "            batch_labels = batch_labels.to(DEVICE)\n",
    "            batch_pitchhnr = batch_pitchhnr.to(DEVICE)\n",
    "            batch_global = batch_global.to(DEVICE)\n",
    "            batch_mfcc = batch_mfcc.to(DEVICE)\n",
    "\n",
    "            # Forward pass: Get model outputs (logits)\n",
    "            logits = model(batch_pitchhnr, batch_lengths, batch_global, batch_mfcc)\n",
    "            \n",
    "            # Calculate loss for the current batch\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            total_loss += loss.item() * batch_labels.size(0) # Accumulate loss, weighted by batch size\n",
    "\n",
    "            # for EER\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            for i in range(len(batch_labels)):\n",
    "                current_label = batch_labels[i]\n",
    "                current_score = probabilities[i]\n",
    "\n",
    "                if current_label == LABEL_BONAFIDE:\n",
    "                    scores_bonafide.append(current_score[LABEL_BONAFIDE].cpu())     # numpy is cpu only, need to move tensor from gpu\n",
    "                elif current_label == LABEL_SPOOF:\n",
    "                    scores_spoof.append(current_score[LABEL_BONAFIDE].cpu())\n",
    "            \n",
    "            total_samples += batch_labels.size(0) # Count number of samples in this batch\n",
    "\n",
    "    average_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    scores_bonafide_np = np.array(scores_bonafide)    \n",
    "    scores_spoof_np = np.array(scores_spoof)\n",
    "    eer, threshold = em.compute_eer(scores_bonafide_np, scores_spoof_np)\n",
    "\n",
    "    # NOTE: TBD - compute the confusion matrix\n",
    "    all_scores = np.concatenate((scores_bonafide_np, scores_spoof_np))\n",
    "    labels_true = np.concatenate((np.ones_like(scores_bonafide_np), np.zeros_like(scores_spoof_np)))\n",
    "    labels_pred = (all_scores >= threshold).astype(int)\n",
    "    \n",
    "    return average_loss, eer, threshold, labels_true, labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05672159",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dca569",
   "metadata": {},
   "source": [
    ">note: in wandb, scalers logs for every epoch, plots get overwritten (but still saved in artifacts?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c10873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, dev_dataloader, criterion, optimizer, num_epochs,\n",
    "                min_eer, best_model_filename):\n",
    "\n",
    "    print(f\"Training started on device: {DEVICE}\")\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    # Initial metric dictionary for the progress bar\n",
    "    metric_dict = {'train_loss': 'N/A', 'val_loss': 'N/A', 'val_eer': 'N/A', 'val_threshold': 'N/A'}\n",
    "\n",
    "    # Evaluate on validation set first to get a baseline\n",
    "    print(\"Evaluating on validation set before training...\")\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    val_loss_initial, val_eer_initial, threshold_initial, labels_true, labels_pred = evaluate_classifier(dev_dataloader, model, criterion)\n",
    "    metric_dict.update({'val_loss': f'{val_loss_initial:.3f}', 'val_eer': f'{val_eer_initial*100:.2f}%', 'val_threshold': f'{threshold_initial*100:.2f}%'})\n",
    "    print(f\"Initial Validation - Loss: {val_loss_initial:.4f}, EER: {val_eer_initial*100:.2f}%, Threshold: {threshold_initial*100:.2f}%\")\n",
    "\n",
    "    # Progress bar setup\n",
    "    total_steps = num_epochs * len(train_dataloader)\n",
    "    pbar = tqdm(total=total_steps, initial=0, postfix=metric_dict, unit=\"batch\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode (enables dropout, etc.)\n",
    "        pbar.set_description(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        num_train_batches = 0\n",
    "\n",
    "        for batch_labels, batch_lengths, batch_pitchhnr, batch_global, batch_mfcc in train_dataloader:\n",
    "            # Move data to the specified device\n",
    "            # batch_lengths are used by pack_padded_sequence which expects them on CPU\n",
    "            batch_labels = batch_labels.to(DEVICE)\n",
    "            batch_pitchhnr = batch_pitchhnr.to(DEVICE)\n",
    "            batch_global = batch_global.to(DEVICE)\n",
    "            batch_mfcc = batch_mfcc.to(DEVICE)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: Get model outputs (logits)\n",
    "            logits = model(batch_pitchhnr, batch_lengths, batch_global, batch_mfcc)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            # --- FOR GRADIENT CLIPPING ---\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.01) # Start with max_norm=1.0 or 0.5\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics for progress bar and logging\n",
    "            running_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "            \n",
    "            pbar.update(1) # Increment progress bar by one batch\n",
    "            metric_dict.update({'train_loss': f'{loss.item():.3f}'}) # Current batch loss\n",
    "            pbar.set_postfix(metric_dict)\n",
    "        \n",
    "        # Calculate average training loss for the epoch\n",
    "        avg_epoch_train_loss = running_train_loss / num_train_batches if num_train_batches > 0 else 0.0\n",
    "        metric_dict.update({'train_loss': f'{avg_epoch_train_loss:.3f}'}) # Average epoch loss\n",
    "        \n",
    "        # Evaluate on validation set after each epoch\n",
    "        avg_val_loss, val_eer, val_threshold, labels_true, labels_pred = evaluate_classifier(dev_dataloader, model, criterion)\n",
    "        \n",
    "        # Update with latest validation metrics\n",
    "        metric_dict.update({'val_loss': f'{avg_val_loss:.3f}', 'val_eer': f'{val_eer*100:.2f}%', 'val_threshold': f'{val_threshold*100:.2f}%'})\n",
    "        pbar.set_postfix(metric_dict)\n",
    "        \n",
    "        # Optional: Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1} Summary: Avg Train Loss: {avg_epoch_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, EER: {val_eer*100:.2f}%, Threshold: {val_threshold*100:.2f}%\")\n",
    "\n",
    "        # log the train\\dev loss and the eer & threshold\n",
    "        run.log({\"train_loss\": avg_epoch_train_loss, \"dev_loss\": avg_val_loss, \n",
    "                   \"dev_eer\": val_eer, \"dev_threshold\":val_threshold, \"epoch\": epoch + 1})\n",
    "        \n",
    "        # update min eer and optimal model\n",
    "        if val_eer < min_eer:\n",
    "            min_eer = val_eer\n",
    "            torch.save(model.state_dict(), best_model_filename)\n",
    "            print(f\"Epoch {epoch+1}: New best model saved to '{best_model_filename}' with EER: {min_eer:.4f}\")\n",
    "\n",
    "            run.summary['best_validation_eer'] = min_eer\n",
    "            run.summary['best_eer_epoch'] = epoch + 1\n",
    "            run.summary['validation_loss_at_best_eer'] = avg_val_loss\n",
    "\n",
    "            # log the report and confusion matrix\n",
    "            class_names = ['SPOOF', 'BONAFIDE']     #NOTE: the order matters, need to match labels\n",
    "            report_columns =  [\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"]\n",
    "            class_report = classification_report(labels_true, labels_pred, labels=[0, 1],\n",
    "                                        target_names=class_names).splitlines()\n",
    "            report_table = []\n",
    "            for line in class_report[2:(len(class_names)+2)]:\n",
    "                report_table.append(line.split())\n",
    "            run.log({\"Confusion Matix\": wandb.plot.confusion_matrix(y_true=labels_true, preds=labels_pred, class_names=class_names),\n",
    "                    \"Classification Report\": wandb.Table(data=report_table, columns=report_columns)})\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"Training finished.\")\n",
    "    return min_eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2c89dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started on device: cuda\n",
      "Evaluating on validation set before training...\n",
      "Initial Validation - Loss: 0.6217, EER: 55.73%, Threshold: 45.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10222e8b5e94096b947d9b2912821a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142500 [00:00<?, ?batch/s, train_loss=N/A, val_eer=55.73%, val_loss=0.622, val_threshold=45…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary: Avg Train Loss: 0.1112, Val Loss: 0.0540, EER: 3.30%, Threshold: 8.00%\n",
      "Epoch 1: New best model saved to 'best_model' with EER: 0.0330\n",
      "\n",
      "Epoch 2 Summary: Avg Train Loss: 0.0299, Val Loss: 0.1605, EER: 3.61%, Threshold: 0.00%\n",
      "\n",
      "Epoch 3 Summary: Avg Train Loss: 0.0127, Val Loss: 0.0844, EER: 2.04%, Threshold: 56.34%\n",
      "Epoch 3: New best model saved to 'best_model' with EER: 0.0204\n",
      "\n",
      "Epoch 4 Summary: Avg Train Loss: 0.0059, Val Loss: 0.1216, EER: 1.96%, Threshold: 0.00%\n",
      "Epoch 4: New best model saved to 'best_model' with EER: 0.0196\n",
      "\n",
      "Epoch 5 Summary: Avg Train Loss: 0.0045, Val Loss: 0.0496, EER: 1.76%, Threshold: 0.02%\n",
      "Epoch 5: New best model saved to 'best_model' with EER: 0.0176\n",
      "\n",
      "Epoch 6 Summary: Avg Train Loss: 0.0046, Val Loss: 0.0918, EER: 3.18%, Threshold: 0.76%\n",
      "\n",
      "Epoch 7 Summary: Avg Train Loss: 0.0040, Val Loss: 0.1330, EER: 2.20%, Threshold: 0.00%\n",
      "\n",
      "Epoch 8 Summary: Avg Train Loss: 0.0018, Val Loss: 0.1118, EER: 1.14%, Threshold: 96.26%\n",
      "Epoch 8: New best model saved to 'best_model' with EER: 0.0114\n",
      "\n",
      "Epoch 9 Summary: Avg Train Loss: 0.0029, Val Loss: 0.4394, EER: 2.16%, Threshold: 0.00%\n",
      "\n",
      "Epoch 10 Summary: Avg Train Loss: 0.0026, Val Loss: 0.4470, EER: 1.95%, Threshold: 0.00%\n",
      "\n",
      "Epoch 11 Summary: Avg Train Loss: 0.0021, Val Loss: 0.0652, EER: 1.84%, Threshold: 0.03%\n",
      "\n",
      "Epoch 12 Summary: Avg Train Loss: 0.0023, Val Loss: 0.0479, EER: 1.41%, Threshold: 1.03%\n",
      "\n",
      "Epoch 13 Summary: Avg Train Loss: 0.0011, Val Loss: 0.0854, EER: 1.34%, Threshold: 0.00%\n",
      "\n",
      "Epoch 14 Summary: Avg Train Loss: 0.0011, Val Loss: 0.1306, EER: 1.84%, Threshold: 0.00%\n",
      "\n",
      "Epoch 15 Summary: Avg Train Loss: 0.0017, Val Loss: 0.0976, EER: 1.53%, Threshold: 0.00%\n",
      "\n",
      "Epoch 16 Summary: Avg Train Loss: 0.0008, Val Loss: 0.0780, EER: 1.65%, Threshold: 0.00%\n",
      "\n",
      "Epoch 17 Summary: Avg Train Loss: 0.0016, Val Loss: 0.0909, EER: 1.01%, Threshold: 0.00%\n",
      "Epoch 17: New best model saved to 'best_model' with EER: 0.0101\n",
      "\n",
      "Epoch 18 Summary: Avg Train Loss: 0.0004, Val Loss: 2.2949, EER: 5.15%, Threshold: 100.00%\n",
      "\n",
      "Epoch 19 Summary: Avg Train Loss: 0.0006, Val Loss: 0.0767, EER: 1.53%, Threshold: 0.00%\n",
      "\n",
      "Epoch 20 Summary: Avg Train Loss: 0.0008, Val Loss: 0.1947, EER: 1.69%, Threshold: 0.00%\n",
      "\n",
      "Epoch 21 Summary: Avg Train Loss: 0.0011, Val Loss: 0.2825, EER: 1.41%, Threshold: 0.00%\n",
      "\n",
      "Epoch 22 Summary: Avg Train Loss: 0.0009, Val Loss: 0.0805, EER: 1.65%, Threshold: 0.00%\n",
      "\n",
      "Epoch 23 Summary: Avg Train Loss: 0.0007, Val Loss: 1.1026, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 24 Summary: Avg Train Loss: 0.0009, Val Loss: 0.0999, EER: 2.04%, Threshold: 2.72%\n",
      "\n",
      "Epoch 25 Summary: Avg Train Loss: 0.0007, Val Loss: 0.0670, EER: 1.65%, Threshold: 0.00%\n",
      "\n",
      "Epoch 26 Summary: Avg Train Loss: 0.0008, Val Loss: 0.1666, EER: 1.34%, Threshold: 0.00%\n",
      "\n",
      "Epoch 27 Summary: Avg Train Loss: 0.0005, Val Loss: 0.2273, EER: 1.53%, Threshold: 0.00%\n",
      "\n",
      "Epoch 28 Summary: Avg Train Loss: 0.0016, Val Loss: 0.0640, EER: 1.14%, Threshold: 0.00%\n",
      "\n",
      "Epoch 29 Summary: Avg Train Loss: 0.0012, Val Loss: 0.1892, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 30 Summary: Avg Train Loss: 0.0012, Val Loss: 0.0924, EER: 1.14%, Threshold: 0.00%\n",
      "\n",
      "Epoch 31 Summary: Avg Train Loss: 0.0011, Val Loss: 0.0815, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 32 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1258, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 33 Summary: Avg Train Loss: 0.0012, Val Loss: 0.1474, EER: 1.02%, Threshold: 99.65%\n",
      "\n",
      "Epoch 34 Summary: Avg Train Loss: 0.0011, Val Loss: 0.1240, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 35 Summary: Avg Train Loss: 0.0009, Val Loss: 0.3310, EER: 1.53%, Threshold: 0.00%\n",
      "\n",
      "Epoch 36 Summary: Avg Train Loss: 0.0010, Val Loss: 0.0663, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 37 Summary: Avg Train Loss: 0.0000, Val Loss: 0.0929, EER: 1.22%, Threshold: 0.00%\n",
      "\n",
      "Epoch 38 Summary: Avg Train Loss: 0.0008, Val Loss: 0.1094, EER: 1.25%, Threshold: 0.00%\n",
      "\n",
      "Epoch 39 Summary: Avg Train Loss: 0.0009, Val Loss: 0.1331, EER: 1.38%, Threshold: 0.00%\n",
      "\n",
      "Epoch 40 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1259, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 41 Summary: Avg Train Loss: 0.0009, Val Loss: 0.1512, EER: 1.49%, Threshold: 0.00%\n",
      "\n",
      "Epoch 42 Summary: Avg Train Loss: 0.0010, Val Loss: 0.2070, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 43 Summary: Avg Train Loss: 0.0002, Val Loss: 0.0920, EER: 1.21%, Threshold: 0.00%\n",
      "\n",
      "Epoch 44 Summary: Avg Train Loss: 0.0004, Val Loss: 0.0788, EER: 0.94%, Threshold: 0.00%\n",
      "Epoch 44: New best model saved to 'best_model' with EER: 0.0094\n",
      "\n",
      "Epoch 45 Summary: Avg Train Loss: 0.0006, Val Loss: 0.1203, EER: 0.98%, Threshold: 0.00%\n",
      "\n",
      "Epoch 46 Summary: Avg Train Loss: 0.0007, Val Loss: 0.1012, EER: 0.83%, Threshold: 0.00%\n",
      "Epoch 46: New best model saved to 'best_model' with EER: 0.0083\n",
      "\n",
      "Epoch 47 Summary: Avg Train Loss: 0.0006, Val Loss: 0.0799, EER: 0.94%, Threshold: 0.00%\n",
      "\n",
      "Epoch 48 Summary: Avg Train Loss: 0.0010, Val Loss: 0.0868, EER: 1.45%, Threshold: 0.00%\n",
      "\n",
      "Epoch 49 Summary: Avg Train Loss: 0.0002, Val Loss: 0.0524, EER: 1.10%, Threshold: 0.00%\n",
      "\n",
      "Epoch 50 Summary: Avg Train Loss: 0.0018, Val Loss: 0.8371, EER: 1.41%, Threshold: 0.00%\n",
      "\n",
      "Epoch 51 Summary: Avg Train Loss: 0.0007, Val Loss: 0.1540, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 52 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1159, EER: 1.18%, Threshold: 0.00%\n",
      "\n",
      "Epoch 53 Summary: Avg Train Loss: 0.0007, Val Loss: 0.0625, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 54 Summary: Avg Train Loss: 0.0002, Val Loss: 0.0539, EER: 1.22%, Threshold: 0.00%\n",
      "\n",
      "Epoch 55 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1450, EER: 1.69%, Threshold: 0.00%\n",
      "\n",
      "Epoch 56 Summary: Avg Train Loss: 0.0007, Val Loss: 0.0832, EER: 0.97%, Threshold: 0.00%\n",
      "\n",
      "Epoch 57 Summary: Avg Train Loss: 0.0007, Val Loss: 0.0864, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 58 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1338, EER: 1.14%, Threshold: 0.00%\n",
      "\n",
      "Epoch 59 Summary: Avg Train Loss: 0.0008, Val Loss: 0.3494, EER: 1.34%, Threshold: 0.00%\n",
      "\n",
      "Epoch 60 Summary: Avg Train Loss: 0.0004, Val Loss: 0.1255, EER: 1.13%, Threshold: 0.00%\n",
      "\n",
      "Epoch 61 Summary: Avg Train Loss: 0.0005, Val Loss: 0.0768, EER: 1.10%, Threshold: 0.00%\n",
      "\n",
      "Epoch 62 Summary: Avg Train Loss: 0.0006, Val Loss: 0.0779, EER: 0.91%, Threshold: 0.00%\n",
      "\n",
      "Epoch 63 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1158, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 64 Summary: Avg Train Loss: 0.0011, Val Loss: 0.0953, EER: 1.06%, Threshold: 0.00%\n",
      "\n",
      "Epoch 65 Summary: Avg Train Loss: 0.0003, Val Loss: 0.0470, EER: 0.98%, Threshold: 0.00%\n",
      "\n",
      "Epoch 66 Summary: Avg Train Loss: 0.0007, Val Loss: 0.1392, EER: 1.06%, Threshold: 0.00%\n",
      "\n",
      "Epoch 67 Summary: Avg Train Loss: 0.0006, Val Loss: 0.1363, EER: 1.33%, Threshold: 0.00%\n",
      "\n",
      "Epoch 68 Summary: Avg Train Loss: 0.0013, Val Loss: 0.1287, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 69 Summary: Avg Train Loss: 0.0004, Val Loss: 0.0687, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 70 Summary: Avg Train Loss: 0.0012, Val Loss: 0.1224, EER: 1.14%, Threshold: 0.00%\n",
      "\n",
      "Epoch 71 Summary: Avg Train Loss: 0.0006, Val Loss: 0.1500, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 72 Summary: Avg Train Loss: 0.0004, Val Loss: 0.0640, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 73 Summary: Avg Train Loss: 0.0003, Val Loss: 0.1308, EER: 1.10%, Threshold: 0.00%\n",
      "\n",
      "Epoch 74 Summary: Avg Train Loss: 0.0011, Val Loss: 0.1099, EER: 2.04%, Threshold: 0.00%\n",
      "\n",
      "Epoch 75 Summary: Avg Train Loss: 0.0005, Val Loss: 0.1917, EER: 1.22%, Threshold: 0.00%\n",
      "\n",
      "Epoch 76 Summary: Avg Train Loss: 0.0006, Val Loss: 0.0608, EER: 0.89%, Threshold: 0.00%\n",
      "\n",
      "Epoch 77 Summary: Avg Train Loss: 0.0003, Val Loss: 0.0851, EER: 0.98%, Threshold: 0.00%\n",
      "\n",
      "Epoch 78 Summary: Avg Train Loss: 0.0000, Val Loss: 0.2546, EER: 1.21%, Threshold: 0.00%\n",
      "\n",
      "Epoch 79 Summary: Avg Train Loss: 0.0013, Val Loss: 0.1331, EER: 1.41%, Threshold: 0.00%\n",
      "\n",
      "Epoch 80 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1194, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 81 Summary: Avg Train Loss: 0.0001, Val Loss: 0.2620, EER: 1.03%, Threshold: 0.00%\n",
      "\n",
      "Epoch 82 Summary: Avg Train Loss: 0.0008, Val Loss: 0.6705, EER: 1.49%, Threshold: 100.00%\n",
      "\n",
      "Epoch 83 Summary: Avg Train Loss: 0.0001, Val Loss: 0.1997, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 84 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1646, EER: 1.22%, Threshold: 0.00%\n",
      "\n",
      "Epoch 85 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1583, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 86 Summary: Avg Train Loss: 0.0017, Val Loss: 0.0912, EER: 1.06%, Threshold: 0.00%\n",
      "\n",
      "Epoch 87 Summary: Avg Train Loss: 0.0003, Val Loss: 0.1137, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 88 Summary: Avg Train Loss: 0.0002, Val Loss: 0.1064, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 89 Summary: Avg Train Loss: 0.0002, Val Loss: 0.3034, EER: 1.26%, Threshold: 0.00%\n",
      "\n",
      "Epoch 90 Summary: Avg Train Loss: 0.0006, Val Loss: 0.3443, EER: 1.45%, Threshold: 0.00%\n",
      "\n",
      "Epoch 91 Summary: Avg Train Loss: 0.0003, Val Loss: 0.2317, EER: 1.06%, Threshold: 0.00%\n",
      "\n",
      "Epoch 92 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1316, EER: 0.98%, Threshold: 0.00%\n",
      "\n",
      "Epoch 93 Summary: Avg Train Loss: 0.0004, Val Loss: 0.2856, EER: 1.02%, Threshold: 0.00%\n",
      "\n",
      "Epoch 94 Summary: Avg Train Loss: 0.0004, Val Loss: 0.1447, EER: 1.37%, Threshold: 0.00%\n",
      "\n",
      "Epoch 95 Summary: Avg Train Loss: 0.0001, Val Loss: 0.1269, EER: 1.09%, Threshold: 0.00%\n",
      "\n",
      "Epoch 96 Summary: Avg Train Loss: 0.0004, Val Loss: 0.1826, EER: 1.57%, Threshold: 0.00%\n",
      "\n",
      "Epoch 97 Summary: Avg Train Loss: 0.0003, Val Loss: 0.2291, EER: 1.30%, Threshold: 0.00%\n",
      "\n",
      "Epoch 98 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1238, EER: 1.18%, Threshold: 0.00%\n",
      "\n",
      "Epoch 99 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1467, EER: 1.22%, Threshold: 0.00%\n",
      "\n",
      "Epoch 100 Summary: Avg Train Loss: 0.0000, Val Loss: 0.1444, EER: 1.19%, Threshold: 0.00%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = config.epochs\n",
    "min_eer = float('inf')\n",
    "best_model_filename = 'best_model'  #tbc\n",
    "\n",
    "min_eer = train_model(model, train_dataloader, dev_dataloader, criterion, optimizer, NUM_EPOCHS,\n",
    "            min_eer, best_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7ece4",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2840319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging the best model (best_model) to W&B Artifacts...\n",
      "Best model logged as W&B Artifact.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_eer</td><td>█▄▄▃▂▃▃▃▃▂▃▂▂▂▂▂▂▁▂▃▂▂▁▁▂▂▂▂▁▂▂▃▂▁▁▂▁▂▃▂</td></tr><tr><td>dev_loss</td><td>▁▂▁▂▂▁▂▁▁▂▁▂▂▂▂▁▁█▂▁▁▁▄▂▂▂▂▁▁▂▂▂▁▃▄▃▂▃▂▂</td></tr><tr><td>dev_threshold</td><td>▁▅▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train_loss</td><td>█▃▂▃▂▁▂▁▂▁▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eer_epoch</td><td>46</td></tr><tr><td>best_validation_eer</td><td>0.00831</td></tr><tr><td>dev_eer</td><td>0.01185</td></tr><tr><td>dev_loss</td><td>0.14437</td></tr><tr><td>dev_threshold</td><td>0.0</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>train_loss</td><td>0.0</td></tr><tr><td>validation_loss_at_best_eer</td><td>0.10119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">COMBINED_MODEL_1</strong> at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/yxvyt5pb' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake/runs/yxvyt5pb</a><br> View project at: <a href='https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake' target=\"_blank\">https://wandb.ai/qianyue-university-of-stuttgart/teamlab_deepfake</a><br>Synced 5 W&B file(s), 16 media file(s), 32 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250624_151648-yxvyt5pb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished.\n"
     ]
    }
   ],
   "source": [
    "if min_eer != float('inf'):\n",
    "    print(f\"Logging the best model ({best_model_filename}) to W&B Artifacts...\")\n",
    "    best_model_artifact = wandb.Artifact(\n",
    "        name=f\"{run.id}-best-model\", # Using run ID for uniqueness\n",
    "        type=\"model\",\n",
    "        description=f\"Best model according to EER ({min_eer:.4f}) achieved at epoch {run.summary.get('best_eer_epoch', 'N/A')}.\",\n",
    "        metadata={\"best_eer\": min_eer, \"epoch_of_best_eer\": run.summary.get('best_eer_epoch', 'N/A')}\n",
    "    )\n",
    "    best_model_artifact.add_file(best_model_filename) # Add the saved file\n",
    "    wandb.run.log_artifact(best_model_artifact, aliases=[\"best_eer_model\"]) # Add an alias\n",
    "    print(\"Best model logged as W&B Artifact.\")\n",
    "else:\n",
    "    print(\"No model was saved as best_eer did not improve from its initial value.\")\n",
    "\n",
    "run.finish()\n",
    "\n",
    "print(\"W&B run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0200f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
