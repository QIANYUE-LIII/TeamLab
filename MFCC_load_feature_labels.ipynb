{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb70628e-9627-4c33-a66a-a38af6f3e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31616638-0bf8-4565-bacc-0a166727d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(features_dir, label_file, flatten=True):\n",
    "\n",
    "    with open(label_file, 'rb') as f:\n",
    "        label_dict = pickle.load(f)  \n",
    "    X, y = [], []\n",
    "    # dataset = []\n",
    "    # target_len = 0\n",
    "    # shapes = []\n",
    "    # print(os.listdir(features_dir))\n",
    "    # print(label_dict)\n",
    "\n",
    "    # reading files' names in mfcc_train (e.g. 'LA_T_7500588.npy', 'LA_T_1631305.npy', ...)\n",
    "    for fname in os.listdir(features_dir):\n",
    "        if not fname.endswith('.npy'):\n",
    "            continue\n",
    "\n",
    "        # store utt_id by deleting .npy (final form: 'LA_T_7500588' )\n",
    "        utt_id = fname.replace('.npy', '')\n",
    "        # ../data/features/mfcc_train/LA_T_7500588.npy\n",
    "        feature_path = os.path.join(features_dir, fname)\n",
    "        \n",
    "        with open(feature_path, 'rb') as f:\n",
    "            # feat.shape = [n_mfcc, T] (n_mfcc=100 -> 100; aduio's different length -> T)\n",
    "            feat = np.load(f)\n",
    "            # T = feat.shape[1]\n",
    "            # print(shape[1])\n",
    "            # find largest T\n",
    "            # if target_len < T:\n",
    "            #     target_len = T\n",
    "\n",
    "    # print(target_len)\n",
    "    # processing feat (flatten or not; padding)\n",
    "    # for fname in os.listdir(features_dir):\n",
    "        # if not fname.endswith('.npy'):\n",
    "        #     continue\n",
    "\n",
    "        # store utt_id by deleting .npy (final form: 'LA_T_7500588' )\n",
    "        # utt_id = fname.replace('.npy', '')\n",
    "        # ../data/features/mfcc_train/LA_T_7500588.npy\n",
    "        # feature_path = os.path.join(features_dir, fname)\n",
    "        \n",
    "        # with open(feature_path, 'rb') as f:\n",
    "            # feat.shape = [n_mfcc, T] (n_mfcc=100 -> 100; aduio's different length -> T)\n",
    "            # feat = np.load(feature_path)\n",
    "            # if feat.shape[1] == target_len:\n",
    "            #     continue\n",
    "            # else:\n",
    "            #     pad_width = target_len - feat.shape[1]\n",
    "            #     feat = np.pad(feat, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "            if flatten:\n",
    "                feat = feat.flatten()\n",
    "            \n",
    "            \n",
    "            if utt_id in label_dict:       \n",
    "                X.append(feat)\n",
    "                y.append(label_dict[utt_id])\n",
    "                \n",
    "                # dataset.append({\n",
    "                #     \"file_name\": utt_id,\n",
    "                #     \"features\": feat,\n",
    "                #     \"label\": label_dict[utt_id]\n",
    "                # })\n",
    "            else:\n",
    "                continue\n",
    "    # print(X, y)\n",
    "    # print(shapes[:10])\n",
    "    # print(target_len)\n",
    "    \n",
    "\n",
    "    return X,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b999f9c-cb92-479e-8ea4-d5772e183c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "def save_features(save_dir, X, y, X_path, y_path):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(save_dir, X_path), 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    with open(os.path.join(save_dir, y_path), 'wb') as f:\n",
    "        pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce7b8e0-7e60-4734-b1b8-25e8f45a66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mfcc for svm\n",
    "X_train, y_train = load_dataset(\n",
    "    features_dir='../data/features/mfcc_train/mfcc_train_30',\n",
    "    label_file='../data/labels/train_labels.pkl',\n",
    "    flatten=True  # or False if using CNN \n",
    ")\n",
    "\n",
    "# save 30_mfcc svm features (training)\n",
    "save_features(save_dir = '../data/dataset/mfcc_train/mfcc_train_30_dataset' , X = X_train, y = y_train, X_path = 'X_train.pkl', y_path = 'y_path.pkl')\n",
    "\n",
    "# 30 mfcc for svm (validation)\n",
    "X_dev_30, y_dev_30 = load_dataset(\n",
    "    features_dir='../data/features/mfcc_dev/mfcc_dev_30',\n",
    "    label_file='../data/labels/dev_labels.pkl',\n",
    "    flatten=True  # or False if using CNN \n",
    ")\n",
    "\n",
    "# save 60_mfcc svm features (validation)\n",
    "save_features(save_dir = '../data/dataset/mfcc_dev_30_svm' , X = X_dev_30, y = y_dev_30, X_path = 'X_dev_30.pkl', y_path = 'y_dev_30.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd3d34e0-0039-46bd-8a6d-118ed2b5ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 mfcc for svm (training)\n",
    "X_train_60, y_train_60 = load_dataset(\n",
    "    features_dir='../data/features/mfcc_train/mfcc_train_60',\n",
    "    label_file='../data/labels/train_labels.pkl',\n",
    "    flatten=True  # or False if using CNN \n",
    ")\n",
    "\n",
    "# save 60 mfcc svm features (training)\n",
    "save_features(save_dir = '../data/dataset/mfcc_train_60_svm' , X = X_train_60, y = y_train_60, X_path = 'X_train_60.pkl', y_path='y_train_60.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b50efe2-3ed4-4aa6-95ac-9acf69320219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 mfcc for CNN (training)\n",
    "X_train_60_cnn, y_train_60_cnn = load_dataset(\n",
    "    features_dir='../data/features/mfcc_train/mfcc_train_60',\n",
    "    label_file='../data/labels/train_labels.pkl',\n",
    "    flatten=False  # or False if using CNN \n",
    ")\n",
    "\n",
    "# save 60 mfcc cnn features (training)\n",
    "save_features(save_dir = '../data/dataset/mfcc_train_60_cnn' , X = X_train_60_cnn, y = y_train_60_cnn, X_path = 'X_train_60_cnn', y_path = 'y_train_cnn.pkl')\n",
    "\n",
    "# 60 mfcc for CNN (validation)\n",
    "X_dev_60_cnn, y_dev_60_cnn = load_dataset(\n",
    "    features_dir='../data/features/mfcc_dev/mfcc_dev_60',\n",
    "    label_file='../data/labels/dev_labels.pkl',\n",
    "    flatten=False  # or False if using CNN \n",
    ")\n",
    "\n",
    "# save 60 mfcc cnn features (validation)\n",
    "save_features(save_dir = '../data/dataset/mfcc_dev_60_cnn', X = X_dev_60_cnn, y = y_dev_60_cnn, X_path = 'X_dev_60_cnn.pkl', y_path = 'y_dev_60_cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37295afe-8b24-47eb-a284-0dfeb3912ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda]",
   "language": "python",
   "name": "conda-env-.conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
