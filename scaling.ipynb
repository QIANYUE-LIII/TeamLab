{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba35d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a214ca",
   "metadata": {},
   "source": [
    "### scaling for one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling for sequential data (pitch & hnr)\n",
    "def get_train_seq_minMax(train_data):\n",
    "    max = float('-inf')\n",
    "    min = float('inf')\n",
    "\n",
    "    # find the max and min\n",
    "    # each line is np.ndarray containing a sequence of floats\n",
    "    for line in train_data:\n",
    "        max_line = np.nanmax(line)  # ignore nans\n",
    "        min_line = np.nanmin(line)\n",
    "        if max_line > max:\n",
    "            max = max_line\n",
    "        if min_line < min:\n",
    "            min = min_line\n",
    "    print(f\"the max value is {max}\")\n",
    "    print(f\"the min value is {min}\")\n",
    "\n",
    "    ### faster if the size of arrays is not that big\n",
    "    # all_values = np.concatenate([arr for arr in feature if arr.size > 0])\n",
    "    # min = np.min(all_values)\n",
    "    # max = np.max(all_values)\n",
    "    return min, max\n",
    "\n",
    "def scaling_seq(feature, min, max):\n",
    "    \n",
    "    # scaling\n",
    "    scaled_feature = []\n",
    "    difference = max - min\n",
    "    for line in feature:\n",
    "        scaled_list = []\n",
    "        for i in range(len(line)):\n",
    "            scaled_list.append((line[i] - min) / difference)\n",
    "        scaled_feature.append(np.array(scaled_list))\n",
    "\n",
    "    return(scaled_feature)\n",
    "\n",
    "\n",
    "# scaling for non-sequential data (jitter & shimmer)\n",
    "def get_train_nonseq_minMax(train_data):\n",
    "    dim = len(train_data[0])\n",
    "    max = [float('-inf')]*dim\n",
    "    min = [float('inf')]*dim\n",
    "\n",
    "    # find the max and min for each dimasion\n",
    "    # each line is np.array containing floats in diffrent dim\n",
    "    for line in train_data:\n",
    "        for i in range(len(line)):\n",
    "            if line[i] > max[i]:\n",
    "                max[i] = line[i]\n",
    "            if line[i] < min[i]:\n",
    "                min[i] = line[i]\n",
    "    print(f\"the max value is {max}\")\n",
    "    print(f\"the min value is {min}\")\n",
    "\n",
    "    return min, max\n",
    "\n",
    "def scaling_nonseq(feature, min, max):\n",
    "    # scaling\n",
    "    scaled_feature = []\n",
    "    difference = [a - b for a,b in zip(max, min)]\n",
    "    for line in feature:\n",
    "        scaled_list = []\n",
    "        for i in range(len(line)):\n",
    "            scaled_list.append((line[i] - min[i]) / difference[i])\n",
    "        scaled_feature.append(np.array(scaled_list))\n",
    "\n",
    "    return scaled_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb25773",
   "metadata": {},
   "source": [
    "### scaling for the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956b74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the dataframe with the scaled ones\n",
    "def processing(df, min, max):\n",
    "    print(f\"---processing pitch---\")\n",
    "    pitch_scaled = scaling_seq(df['PITCH'], min[0], max[0])\n",
    "    print(f\"---processing hnr---\")\n",
    "    hnr_scaled = scaling_seq(df['HNR'], min[1], max[1])\n",
    "    print(f\"---processing jitter---\")\n",
    "    jitter_scaled = scaling_nonseq(df['JITTER'], min[2], max[2])\n",
    "    print(f\"---processing shimmer---\")\n",
    "    shimmer_scaled = scaling_nonseq(df['SHIMMER'], min[3], max[3])\n",
    "\n",
    "    data = {'AUDIO_ID': df['AUDIO_ID'],\n",
    "            'LABEL': df['LABEL'],\n",
    "            'ATTACK_TYPE': df['ATTACK_TYPE'],\n",
    "            'PITCH': pitch_scaled,\n",
    "            'HNR': hnr_scaled,\n",
    "            'JITTER': jitter_scaled,\n",
    "            'SHIMMER': shimmer_scaled}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e763332",
   "metadata": {},
   "source": [
    "### produce new data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04994868",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '~/TeamLab_phonetics/prosody_features_train_wlabel.parquet'\n",
    "dev_path = '~/TeamLab_phonetics/prosody_features_dev_wlabel.parquet'\n",
    "eval_path = '~/TeamLab_phonetics/prosody_features_eval_wlabel.parquet'\n",
    "\n",
    "df_train = pd.read_parquet(train_path, engine='pyarrow')\n",
    "df_dev = pd.read_parquet(dev_path, engine='pyarrow')\n",
    "df_eval = pd.read_parquet(eval_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889e9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max value is 599.9943456812225\n",
      "the min value is 74.92041345964803\n",
      "the max value is 58.399494463862524\n",
      "the min value is -200.0\n",
      "the max value is [0.09882632, 0.0010225201, 0.048410866, 0.07295901, 0.1452326]\n",
      "the min value is [0.004070737, 2.1154045e-05, 0.00074533327, 0.0013134623, 0.0022359998]\n",
      "the max value is [0.30648893, 2.348075, 0.22382307, 0.28442547, 0.8268665, 0.6714692]\n",
      "the min value is [0.028642662, 0.33427465, 0.0052041854, 0.007886035, 0.0037046608, 0.015612557]\n"
     ]
    }
   ],
   "source": [
    "pitch_min, pitch_max = get_train_seq_minMax(df_train['PITCH'])\n",
    "hnr_min, hnr_max = get_train_seq_minMax(df_train['HNR'])\n",
    "jitter_min, jitter_max = get_train_nonseq_minMax(df_train['JITTER'])\n",
    "shimmer_min, shimmer_max = get_train_nonseq_minMax(df_train['SHIMMER'])\n",
    "min = [pitch_min, hnr_min, jitter_min, shimmer_min]\n",
    "max = [pitch_max, hnr_max, jitter_max, shimmer_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ebab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---processing pitch---\n",
      "---processing hnr---\n",
      "---processing jitter---\n",
      "---processing shimmer---\n"
     ]
    }
   ],
   "source": [
    "train_scaled = processing(df_train, min, max)\n",
    "df_train_scaled= pd.DataFrame(train_scaled)\n",
    "#df_train_scaled.to_parquet(\"~/TeamLab_phonetics/prosody_features_train_scaled.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8a5a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---processing pitch---\n",
      "---processing hnr---\n",
      "---processing jitter---\n",
      "---processing shimmer---\n"
     ]
    }
   ],
   "source": [
    "dev_scaled = processing(df_dev, min, max)\n",
    "df_dev_scaled= pd.DataFrame(dev_scaled)\n",
    "df_dev_scaled.to_parquet(\"~/TeamLab_phonetics/prosody_features_dev_scaled.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835610c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---processing pitch---\n",
      "---processing hnr---\n",
      "---processing jitter---\n",
      "---processing shimmer---\n"
     ]
    }
   ],
   "source": [
    "eval_scaled = processing(df_eval, min, max)\n",
    "df_eval_scaled= pd.DataFrame(eval_scaled)\n",
    "df_eval_scaled.to_parquet(\"~/TeamLab_phonetics/prosody_features_eval_scaled.parquet\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7e6dd",
   "metadata": {},
   "source": [
    "### Inspection of the new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbf535",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['PITCH'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_scaled['PITCH'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb65876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AUDIO_ID  LABEL ATTACK_TYPE  \\\n",
      "0  LA_T_1000137      0         A04   \n",
      "1  LA_T_1000406      1           -   \n",
      "2  LA_T_1000648      0         A01   \n",
      "3  LA_T_1000824      0         A04   \n",
      "4  LA_T_1001074      0         A03   \n",
      "\n",
      "                                               PITCH  \\\n",
      "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  [nan, nan, nan, nan, nan, 0.35835335634967486,...   \n",
      "3  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "                                                 HNR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7987432090825...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                              JITTER  \\\n",
      "0  [0.30073947, 0.23022015, 0.26707897, 0.2538646...   \n",
      "1  [0.1494679, 0.09972349, 0.086890295, 0.0791289...   \n",
      "2  [0.13972145, 0.05122372, 0.123514704, 0.096691...   \n",
      "3  [0.28089172, 0.2684494, 0.23122567, 0.24996407...   \n",
      "4  [0.14094485, 0.068655394, 0.07130514, 0.062871...   \n",
      "\n",
      "                                             SHIMMER  \n",
      "0  [0.27033818, 0.33233136, 0.11353744, 0.1519924...  \n",
      "1  [0.13012205, 0.15872449, 0.059600886, 0.081321...  \n",
      "2  [0.28141773, 0.3631905, 0.12680757, 0.17373542...  \n",
      "3  [0.2846507, 0.35503966, 0.13182917, 0.15244015...  \n",
      "4  [0.16095506, 0.21579938, 0.039854582, 0.081848...  \n",
      "              LABEL\n",
      "count  25379.000000\n",
      "mean       0.101659\n",
      "std        0.302205\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_train_scaled.head())\n",
    "print(df_train_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963a78d",
   "metadata": {},
   "source": [
    "### Scaling for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_minMax(train_data_row):\n",
    "    max = float('-inf')\n",
    "    min = float('inf')\n",
    "    for line in train_data_row:\n",
    "        max_line = np.nanmax(line)  # ignore nans\n",
    "        min_line = np.nanmin(line)\n",
    "        if max_line > max:\n",
    "            max = max_line\n",
    "        if min_line < min:\n",
    "            min = min_line\n",
    "    return min, max\n",
    "\n",
    "def get_train_mfcc_minMax(train_data):\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "    for row in train_data:\n",
    "        min, max = get_row_minMax(row)\n",
    "        min_list.append(min)\n",
    "        max_list.append(max)\n",
    "    return min_list, max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_mfcc(train, mfcc_df):\n",
    "    min_list, max_list = get_train_mfcc_minMax(train)\n",
    "    mfcc_list = mfcc_df['MFCC']\n",
    "    mfcc_scaled = []\n",
    "    for i, arr in enumerate(mfcc_list):\n",
    "    # Determine how many rows this specific array has\n",
    "        num_rows = arr.shape[0]\n",
    "        print(f\"\\nProcessing array #{i+1} with {num_rows} rows.\")\n",
    "\n",
    "        # --- This is the key step ---\n",
    "        # Slice the global min/max arrays to get the values for this array's rows\n",
    "        current_mins = min_list[:num_rows]\n",
    "        current_maxs = max_list[:num_rows]\n",
    "\n",
    "        # Reshape for broadcasting (turn 1D array of shape (M,) to a column of shape (M, 1))\n",
    "        mins_col = current_mins[:, np.newaxis]\n",
    "        maxs_col = current_maxs[:, np.newaxis]\n",
    "        \n",
    "        # Calculate the range, handling the division-by-zero case\n",
    "        range_col = maxs_col - mins_col\n",
    "        range_col[range_col == 0] = 1 # Avoid division by zero\n",
    "\n",
    "        # Apply the formula in a single vectorized operation\n",
    "        scaled_arr = (arr - mins_col) / range_col\n",
    "        mfcc_scaled.append(scaled_arr)\n",
    "\n",
    "        data = {\"AUDIO_ID\": mfcc_df[\"AUDIO_ID\"],\n",
    "                \"MFCC\": mfcc_scaled}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82277d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_train_path = \"/home/users1/liqe/TeamLab_phonetics/features_qianru/mfcc_train_df.pkl\"\n",
    "mfcc_dev_path = \"/home/users1/liqe/TeamLab_phonetics/features_qianru/mfcc_dev_df.pkl\"\n",
    "mfcc_train_df = pd.read_pickle(mfcc_train_path)\n",
    "mfcc_dev_df = pd.read_pickle(mfcc_dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c82d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_scaled_df = scaling_mfcc(mfcc_train_df, mfcc_train_df)\n",
    "print(mfcc_scaled_df.info())\n",
    "print(mfcc_scaled_df.describe())\n",
    "print(mfcc_scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_scaled_df.to_pickle(\"/home/users1/liqe/TeamLab_phonetics/features_qianru/mfcc_train_scaled.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
