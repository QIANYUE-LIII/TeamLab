{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d69974",
   "metadata": {},
   "source": [
    "tbd: \n",
    "- tune the parameters\n",
    "    - fine-tune the pitch extraction\n",
    "    - use extracted pitch for hnr (and jitter & shimmer?)  -- no we can't\n",
    "- store jitter and shimmer as one vector?\n",
    "- record the temporal pitches and hnrs\n",
    "- post processing (scaling, zero-padding)\n",
    "- determine which model to use (LSTM? CNN? )\n",
    "- data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47a470",
   "metadata": {},
   "source": [
    "for SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa68d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import parselmouth.praat as praat\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab50402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(sound, pitch_floor, pitch_ceiling):\n",
    "    pitch = sound.to_pitch(\n",
    "            time_step=0.01,\n",
    "            pitch_floor=pitch_floor,\n",
    "            pitch_ceiling=pitch_ceiling,\n",
    "        )\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "    pitch_values[pitch_values == 0] = np.nan\n",
    "\n",
    "    ave_pitch = np.nanmean(pitch_values)\n",
    "    std_pitch = np.nanstd(pitch_values)\n",
    "\n",
    "    return pitch_values, ave_pitch, std_pitch\n",
    "\n",
    "def get_hnr(sound):\n",
    "    harmonicity = sound.to_harmonicity(time_step=0.01)\n",
    "    hnr_values = harmonicity.values.T\n",
    "\n",
    "    ave_hnr = np.nanmean(hnr_values)\n",
    "    std_hnr = np.nanstd(hnr_values)\n",
    "\n",
    "    return hnr_values, ave_hnr, std_hnr\n",
    "\n",
    "def get_gitter_shimmer(sound, pitch_floor, pitch_ceiling):\n",
    "    pointProcess = praat.call(sound, \"To PointProcess (periodic, cc)\", pitch_floor, pitch_ceiling)\n",
    "\n",
    "    # --- Get Jitter Measures ---\n",
    "    lj = praat.call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3) # returns percentage\n",
    "    laj = praat.call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3) # returns seconds\n",
    "    rap = praat.call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3) # returns percentage\n",
    "    ppq5 = praat.call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3) # returns percentage\n",
    "    ddp = praat.call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3) # returns percentage\n",
    "\n",
    "    jitter_values = np.array([\n",
    "        lj, laj, rap, ppq5, ddp\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # --- Get Shimmer Measures ---\n",
    "    ls = praat.call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # returns percentage\n",
    "    lsdb = praat.call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # returns dB\n",
    "    apq3 = praat.call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # returns percentage\n",
    "    apq5 = praat.call([sound, pointProcess], \"Get shimmer (apq5)\",0, 0, 0.0001, 0.02, 1.3, 1.6) # returns percentage\n",
    "    apq11 = praat.call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # returns percentage\n",
    "    dda = praat.call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6) # returns percentage\n",
    "\n",
    "    shimmer_values = np.array([\n",
    "        ls, lsdb, apq3, apq5, apq11, dda\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    return jitter_values, shimmer_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2e885",
   "metadata": {},
   "source": [
    "### Extracting feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ff7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audios(audio_files):\n",
    "\n",
    "    file_ids = []\n",
    "    pitches = []\n",
    "    ave_pitches = []\n",
    "    std_pitches = []\n",
    "    hnrs = []\n",
    "    ave_hnrs = []\n",
    "    std_hnrs = []\n",
    "    jitters = []\n",
    "    shimmers =[]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for audio_file in tqdm(audio_files, desc=\"Processing Audio Files\"):\n",
    "        sound = parselmouth.Sound(audio_file)\n",
    "        #sound.pre_emphasize()   ## don't need this right?\n",
    "        pitch_floor=75\n",
    "        pitch_ceiling=600\n",
    "        \n",
    "        pitch_values, ave_pitch, std_pitch = get_pitch(sound, pitch_floor, pitch_ceiling)\n",
    "        hnr_values, ave_hnr, std_hnr = get_hnr(sound)\n",
    "        jitter, shimmer = get_gitter_shimmer(sound, pitch_floor, pitch_ceiling)\n",
    "\n",
    "        file_ids.append(os.path.basename(audio_file).replace('.flac', ''))\n",
    "        pitches.append(pitch_values)\n",
    "        ave_pitches.append(ave_pitch)\n",
    "        std_pitches.append(std_pitch)\n",
    "        hnrs.append(hnr_values)\n",
    "        ave_hnrs.append(ave_hnr)\n",
    "        std_hnrs.append(std_hnr)\n",
    "        jitters.append(jitter)\n",
    "        shimmers.append(shimmer)\n",
    "\n",
    "\n",
    "        data = {'AUDIO_ID':file_ids,\n",
    "                'PITCH': pitches,\n",
    "                'AVE_PITCH':ave_pitches,\n",
    "                'STD_PITCH':std_pitches,\n",
    "                'HNR':hnrs,\n",
    "                'AVE_HNR':ave_hnrs,\n",
    "                'STD_HNR':std_hnrs,\n",
    "                'JITTER':jitters,\n",
    "                'SHIMMER':shimmers}\n",
    "\n",
    "        i += 1\n",
    "        #if i == 10: break\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45551bdb",
   "metadata": {},
   "source": [
    "### train_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audios = glob.glob('/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/data/ASVSpoof19/LA/ASVspoof2019_LA_train/flac/*.flac')\n",
    "train_features = process_audios(train_audios)\n",
    "\n",
    "df = pd.DataFrame(train_features)\n",
    "\n",
    "df.to_pickle('/home/users1/liqe/TeamLab/prosody_features_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3429fec",
   "metadata": {},
   "source": [
    "### validation_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b1905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files: 100%|██████████| 24986/24986 [13:32<00:00, 30.76it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_audios = glob.glob('/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/data/ASVSpoof19/LA/ASVspoof2019_LA_dev/flac/*.flac')\n",
    "dev_features = process_audios(dev_audios)\n",
    "\n",
    "df = pd.DataFrame(dev_features)\n",
    "\n",
    "# to be changed\n",
    "df.to_pickle('/home/users1/liqe/TeamLab/prosody_features_dev.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26643057",
   "metadata": {},
   "source": [
    "### evaluation_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199aa207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files:   3%|▎         | 2302/71933 [01:12<41:23, 28.04it/s]/tmp/ipykernel_166132/1331028027.py:10: RuntimeWarning: Mean of empty slice\n",
      "  ave_pitch = np.nanmean(pitch_values)\n",
      "/home/users1/liqe/.conda/envs/deepFake/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "Processing Audio Files: 100%|██████████| 71933/71933 [38:27<00:00, 31.17it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_audios = glob.glob('/mount/studenten/arbeitsdaten-studenten1/team-lab-phonetics/2025/data/ASVSpoof19/LA/ASVspoof2019_LA_eval/flac/*.flac')\n",
    "eval_features = process_audios(eval_audios)\n",
    "\n",
    "df = pd.DataFrame(eval_features)\n",
    "\n",
    "# to be changed\n",
    "df.to_pickle('/home/users1/liqe/TeamLab/prosody_features_eval.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab823d4",
   "metadata": {},
   "source": [
    "### Transform pkl file into parquet file & flatten HNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9835f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [[-200.0], [-200.0], [-200.0], [-200.0], [-200.0]]\n",
      "Flattened: nan\n"
     ]
    }
   ],
   "source": [
    "def flatten_list_of_scalar_lists(nested_item):\n",
    "    \"\"\"\n",
    "    Converts a list of single-element lists/arrays (e.g., [[-200.0], [-100.0]])\n",
    "    into a flat list of scalars (e.g., [-200.0, -100.0]).\n",
    "    It can also handle items that are already scalars within the outer list.\n",
    "    \"\"\"\n",
    "    if not isinstance(nested_item, np.ndarray):\n",
    "        # If the input isn't a list at all, return np.nan or an empty list\n",
    "        # depending on how you want to handle unexpected row data.\n",
    "        return np.nan  # Or: return []\n",
    "\n",
    "    flat_list = []\n",
    "    for sub_item in nested_item:\n",
    "        if isinstance(sub_item, (list, np.ndarray)) and len(sub_item) == 1:\n",
    "            element = sub_item[0]\n",
    "            if isinstance(element, (int, float, np.number)):\n",
    "                flat_list.append(element)\n",
    "            else:\n",
    "                # The single element is not a number, append nan\n",
    "                flat_list.append(np.nan)\n",
    "        else:\n",
    "            flat_list.append(np.nan) # Mark as unable to extract a scalar\n",
    "\n",
    "    flat_array = np.array(flat_list)\n",
    "    return flat_array\n",
    "\n",
    "example_hnr_row = [[-200.0], [-200.0], [-200.0], [-200.0], [-200.0]]\n",
    "flattened_result = flatten_list_of_scalar_lists(example_hnr_row)\n",
    "print(f\"Original: {example_hnr_row}\")\n",
    "print(f\"Flattened: {flattened_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5d33580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('/home/users1/liqe/TeamLab/prosody_features_train.pkl')\n",
    "df_train['HNR'] = df_train['HNR'].apply(flatten_list_of_scalar_lists)\n",
    "df_train.to_parquet(\"prosody_features_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf826e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_pickle('/home/users1/liqe/TeamLab/prosody_features_dev.pkl')\n",
    "df_dev['HNR'] = df_dev['HNR'].apply(flatten_list_of_scalar_lists)\n",
    "df_dev.to_parquet(\"prosody_features_dev.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b16b405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_pickle('/home/users1/liqe/TeamLab/prosody_features_eval.pkl')\n",
    "df_eval['HNR'] = df_eval['HNR'].apply(flatten_list_of_scalar_lists)\n",
    "df_eval.to_parquet(\"prosody_features_eval.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e243d1",
   "metadata": {},
   "source": [
    "### Inspect saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cc1e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DataFrame from: /home/users1/liqe/TeamLab_phonetics/prosody_features_train.parquet\n",
      "\n",
      "--- First 5 rows (df.head()) ---\n",
      "       AUDIO_ID                                              PITCH  \\\n",
      "0  LA_T_1000137  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "1  LA_T_1000406  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "2  LA_T_1000648  [nan, nan, nan, nan, nan, 263.08241940297097, ...   \n",
      "3  LA_T_1000824  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "4  LA_T_1001074  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "    AVE_PITCH  STD_PITCH                                                HNR  \\\n",
      "0  129.703246  19.223900  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....   \n",
      "1  151.166201  18.754230  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....   \n",
      "2  240.929243  14.829958  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....   \n",
      "3  106.986026  14.755938  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....   \n",
      "4  194.306253  54.477061  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....   \n",
      "\n",
      "      AVE_HNR     STD_HNR                                             JITTER  \\\n",
      "0  -92.736529  104.786689  [0.03256748, 0.0002516887, 0.013475794, 0.0195...   \n",
      "1 -138.341504   97.483901  [0.018233655, 0.00012101376, 0.0048870053, 0.0...   \n",
      "2  -70.618649  104.616700  [0.017310124, 7.244774e-05, 0.0066327276, 0.00...   \n",
      "3  -97.834652  104.542879  [0.030686794, 0.00028997014, 0.011766828, 0.01...   \n",
      "4 -101.088008  106.743714  [0.017426047, 8.990323e-05, 0.0041441307, 0.00...   \n",
      "\n",
      "                                             SHIMMER  \n",
      "0  [0.10375512, 1.0035236, 0.030025614, 0.0499179...  \n",
      "1  [0.06479659, 0.65391403, 0.018234065, 0.030374...  \n",
      "2  [0.10683353, 1.0656677, 0.032926716, 0.0559307...  \n",
      "3  [0.107731804, 1.0492536, 0.034024533, 0.050041...  \n",
      "4  [0.07336342, 0.76885146, 0.013917149, 0.030520...  \n",
      "\n",
      "--- Last 5 rows (df.tail()) ---\n",
      "           AUDIO_ID                                              PITCH  \\\n",
      "25374  LA_T_9999170  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "25375  LA_T_9999337  [nan, nan, nan, nan, nan, nan, nan, nan, 202.3...   \n",
      "25376  LA_T_9999560  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "25377  LA_T_9999757  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "25378  LA_T_9999995  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
      "\n",
      "        AVE_PITCH  STD_PITCH  \\\n",
      "25374  100.363188   7.164140   \n",
      "25375  191.569031  21.519434   \n",
      "25376  109.429859  20.936661   \n",
      "25377  180.785704  17.229054   \n",
      "25378  121.824993  13.691786   \n",
      "\n",
      "                                                     HNR     AVE_HNR  \\\n",
      "25374  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....  -37.648615   \n",
      "25375  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....  -73.974675   \n",
      "25376  [-200.0, -200.0, -200.0, -200.0, -200.0, -200.... -105.571302   \n",
      "25377  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....  -86.546852   \n",
      "25378  [-200.0, -200.0, -200.0, -200.0, -200.0, -200....  -86.759518   \n",
      "\n",
      "          STD_HNR                                             JITTER  \\\n",
      "25374   91.137573  [0.031615213, 0.0003153758, 0.015267488, 0.017...   \n",
      "25375  105.434615  [0.0186685, 9.704168e-05, 0.0059883054, 0.0084...   \n",
      "25376  102.556558  [0.034276757, 0.00031375213, 0.016177978, 0.01...   \n",
      "25377  107.593381  [0.017480627, 9.678204e-05, 0.0071346704, 0.00...   \n",
      "25378  106.612712  [0.024470527, 0.00020132912, 0.010997435, 0.01...   \n",
      "\n",
      "                                                 SHIMMER  \n",
      "25374  [0.0868622, 0.80183876, 0.031080998, 0.0468844...  \n",
      "25375  [0.13120681, 1.2383447, 0.038537405, 0.0626190...  \n",
      "25376  [0.2007221, 1.6618917, 0.08650279, 0.13055769,...  \n",
      "25377  [0.076279834, 0.8039742, 0.022064963, 0.040088...  \n",
      "25378  [0.11541983, 1.0896341, 0.035451014, 0.0595753...  \n",
      "\n",
      "--- DataFrame Info (df.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25379 entries, 0 to 25378\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   AUDIO_ID   25379 non-null  object \n",
      " 1   PITCH      25379 non-null  object \n",
      " 2   AVE_PITCH  25379 non-null  float64\n",
      " 3   STD_PITCH  25379 non-null  float64\n",
      " 4   HNR        25379 non-null  object \n",
      " 5   AVE_HNR    25379 non-null  float64\n",
      " 6   STD_HNR    25379 non-null  float64\n",
      " 7   JITTER     25379 non-null  object \n",
      " 8   SHIMMER    25379 non-null  object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 1.7+ MB\n",
      "\n",
      "--- Descriptive Statistics (df.describe()) ---\n",
      "          AVE_PITCH     STD_PITCH       AVE_HNR       STD_HNR\n",
      "count  25379.000000  25379.000000  25379.000000  25379.000000\n",
      "mean     170.607974     29.508113   -103.863595    102.861626\n",
      "std       49.056464     22.922477     26.479619      5.292755\n",
      "min       77.203680      2.646952   -176.782555     28.654001\n",
      "25%      120.262290     14.386723   -123.500815    100.822903\n",
      "50%      183.785066     21.586819   -104.873101    104.314100\n",
      "75%      209.399293     36.745529    -84.739334    106.409882\n",
      "max      368.012210    191.849947      0.799162    112.245761\n",
      "\n",
      "--- DataFrame Shape (df.shape) ---\n",
      "Shape: (25379, 9)\n",
      "Number of files (rows): 25379\n",
      "Number of columns (features + metadata): 9\n",
      "\n",
      "--- Column Names (df.columns) ---\n",
      "['AUDIO_ID', 'PITCH', 'AVE_PITCH', 'STD_PITCH', 'HNR', 'AVE_HNR', 'STD_HNR', 'JITTER', 'SHIMMER']\n",
      "\n",
      "--- Missing Values (df.isnull().sum()) ---\n",
      "AUDIO_ID     0\n",
      "PITCH        0\n",
      "AVE_PITCH    0\n",
      "STD_PITCH    0\n",
      "HNR          0\n",
      "AVE_HNR      0\n",
      "STD_HNR      0\n",
      "JITTER       0\n",
      "SHIMMER      0\n",
      "dtype: int64\n",
      "first pitch length is 247\n",
      "first hnr length is 248\n"
     ]
    }
   ],
   "source": [
    "# pkl file\n",
    "#file_path = '/home/users1/liqe/TeamLab_phonetics/prosody_features_train.pkl'\n",
    "\n",
    "# parquet file\n",
    "file_path = '/home/users1/liqe/TeamLab_phonetics/prosody_features_train.parquet'\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file was not found at {file_path}\")\n",
    "    else:\n",
    "        #loaded_df = pd.read_pickle(file_path)\n",
    "        loaded_df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "        print(f\"Successfully loaded DataFrame from: {file_path}\")\n",
    "\n",
    "        # --- Inspect the loaded DataFrame ---\n",
    "\n",
    "        # 1. Display the first few rows\n",
    "        print(\"\\n--- First 5 rows (df.head()) ---\")\n",
    "        print(loaded_df.head())\n",
    "\n",
    "        # 2. Display the last few rows\n",
    "        print(\"\\n--- Last 5 rows (df.tail()) ---\")\n",
    "        print(loaded_df.tail())\n",
    "\n",
    "        # 3. Get concise summary of the DataFrame (index, columns, dtypes, non-null values, memory usage)\n",
    "        print(\"\\n--- DataFrame Info (df.info()) ---\")\n",
    "        loaded_df.info()\n",
    "\n",
    "        # 4. Get descriptive statistics for numerical columns (count, mean, std, min, max, quartiles)\n",
    "        print(\"\\n--- Descriptive Statistics (df.describe()) ---\")\n",
    "        print(loaded_df.describe())\n",
    "\n",
    "        # 5. Check the shape of the DataFrame (number of rows, number of columns)\n",
    "        print(\"\\n--- DataFrame Shape (df.shape) ---\")\n",
    "        print(f\"Shape: {loaded_df.shape}\")\n",
    "        print(f\"Number of files (rows): {loaded_df.shape[0]}\")\n",
    "        print(f\"Number of columns (features + metadata): {loaded_df.shape[1]}\")\n",
    "\n",
    "        # 6. List the column names\n",
    "        print(\"\\n--- Column Names (df.columns) ---\")\n",
    "        print(loaded_df.columns.tolist())\n",
    "\n",
    "        # 7. Check for missing values (NaNs)\n",
    "        print(\"\\n--- Missing Values (df.isnull().sum()) ---\")\n",
    "        print(loaded_df.isnull().sum()) # Sum of True (missing) values per column\n",
    "\n",
    "        # 8. Access a specific column (e.g., 'AVE_PITCH')\n",
    "        # print(\"\\n--- Example: 'AVE_PITCH' column ---\")\n",
    "        # print(loaded_df['AVE_PITCH'].head())\n",
    "\n",
    "        \n",
    "        # check for the length of pitch and hnr\n",
    "        first_pitch = loaded_df['PITCH'].iloc[0]\n",
    "        first_hnr = loaded_df['HNR'].iloc[0]\n",
    "        print(f'first pitch length is {len(first_pitch)}')\n",
    "        print(f'first hnr length is {len(first_hnr)}')\n",
    "\n",
    "        # if not loaded_df['HNR'].empty:\n",
    "\n",
    "        #     sample_entry = 0.0\n",
    "        #     for entry in loaded_df['HNR']:\n",
    "        #         if entry is not None: # and (not isinstance(entry, float) or not np.isnan(entry)): # More robust check if NaNs are floats\n",
    "        #             sample_entry = entry\n",
    "        #             break\n",
    "            \n",
    "        #     if sample_entry is not None:\n",
    "        #         print(f\"Sample HNR entry: {sample_entry}\")\n",
    "        #         print(f\"Type of the HNR entry itself: {type(sample_entry)}\")\n",
    "\n",
    "        #         # If it's a list or tuple, inspect its first element\n",
    "        #         if isinstance(sample_entry, (list, tuple, np.ndarray)) and len(sample_entry) > 0:\n",
    "        #             first_sub_item = sample_entry[0]\n",
    "        #             print(f\"First sub-item: {first_sub_item}\")\n",
    "        #             print(f\"Type of the first sub-item: {type(first_sub_item)}\")\n",
    "\n",
    "        #             # If that sub-item is also a list/tuple, inspect its element\n",
    "        #             print(f\"Type of the element within the sub-item: {type(first_sub_item[0])}\")\n",
    "                    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or inspecting the DataFrame: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5939a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepFake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
